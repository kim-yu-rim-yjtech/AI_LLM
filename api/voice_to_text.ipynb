{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import paramiko\n",
    "from scp import SCPClient\n",
    "import json\n",
    "\n",
    "\n",
    "# Mac 서버 정보\n",
    "MAC_SERVER_HOST = \"61.37.153.212\"  # 서버 IP 주소\n",
    "MAC_SERVER_USER = \"yjtech_mac_machine\"          # Mac 서버 사용자명\n",
    "MAC_SERVER_KEY = \"/home/yjtech/Desktop/LLM/key/id_rsa\"  # Mac 서버 SSH 키 경로\n",
    "REMOTE_SCRIPT_PATH = \"/Users/yjtech_mac_machine/Desktop/yurim/llm/voice_to_text.py\"  # Mac 서버의 스크립트 위치\n",
    "REMOTE_TEMP_DIR = \"/tmp\"  # 서버 임시 디렉토리 (파일 저장 없이 작업 수행)\n",
    "\n",
    "import json\n",
    "\n",
    "def execute_on_mac(maf_idx, file_path):\n",
    "    \"\"\"\n",
    "    Mac 서버로 SSH 연결하여 음성 파일 처리 작업 수행.\n",
    "    결과를 stdout으로 받아 JSON 형태로 반환.\n",
    "    \"\"\"\n",
    "    result = None\n",
    "    ssh = paramiko.SSHClient()\n",
    "    try:\n",
    "        # SSH 클라이언트 설정\n",
    "        ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n",
    "        private_key = paramiko.RSAKey.from_private_key_file(MAC_SERVER_KEY)\n",
    "\n",
    "        # SSH 연결\n",
    "        print(\"Connecting to server...\")\n",
    "        ssh.connect(\n",
    "            hostname=MAC_SERVER_HOST,\n",
    "            username=MAC_SERVER_USER,\n",
    "            pkey=private_key\n",
    "        )\n",
    "        print(\"Connected to server successfully!\")\n",
    "\n",
    "        # 파일 전송 (GCP → Mac)\n",
    "        temp_file_name = os.path.basename(file_path)\n",
    "        remote_temp_path = os.path.join(REMOTE_TEMP_DIR, temp_file_name)\n",
    "\n",
    "        print(f\"Uploading file: {file_path} to {remote_temp_path}\")\n",
    "        with SCPClient(ssh.get_transport()) as scp:\n",
    "            scp.put(file_path, remote_temp_path)\n",
    "\n",
    "        # 명령어 실행: 결과를 stdout으로 출력\n",
    "        command = (\n",
    "            f\"export PATH=/opt/homebrew/bin:$PATH && \"\n",
    "            f\"/opt/anaconda3/envs/venv-keyword/bin/python {REMOTE_SCRIPT_PATH} \"\n",
    "            f\"--maf_idx {maf_idx} --file_path {remote_temp_path}\"\n",
    "        )\n",
    "        print(f\"Executing command: {command}\")\n",
    "        stdin, stdout, stderr = ssh.exec_command(command)\n",
    "        stdout.channel.recv_exit_status()  # 명령어 실행 완료 대기\n",
    "\n",
    "        # 서버 출력 결과 가져오기\n",
    "        output = stdout.read().decode().strip()\n",
    "        error = stderr.read().decode()\n",
    "\n",
    "        if error:\n",
    "            print(f\"Error from server: {error}\")\n",
    "            raise Exception(f\"Error during script execution: {error}\")\n",
    "\n",
    "        print(\"Received output from server:\")\n",
    "        print(output)\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected Error: {e}\")\n",
    "    finally:\n",
    "        ssh.close()\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to server...\n",
      "Connected to server successfully!\n",
      "Uploading file: /home/yjtech/Desktop/LLM/sample_audio.webm to /tmp/sample_audio.webm\n",
      "Executing command: export PATH=/opt/homebrew/bin:$PATH && /opt/anaconda3/envs/venv-keyword/bin/python /Users/yjtech_mac_machine/Desktop/yurim/llm/voice_to_text.py --maf_idx 1 --file_path /tmp/sample_audio.webm\n",
      "Error from server: /opt/anaconda3/envs/venv-keyword/lib/python3.8/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "2024-12-17 14:42:01,850 - INFO: WAV 변환 완료: /var/folders/9w/kjdpzhfn6hdb64q2httmjc1h0000gn/T/tmpkhnil9oi/sample_audio_converted.wav\n",
      "2024-12-17 14:42:01,857 - INFO: 오디오 정규화 완료: /var/folders/9w/kjdpzhfn6hdb64q2httmjc1h0000gn/T/tmpkhnil9oi/sample_audio_normalized.wav\n",
      "2024-12-17 14:42:01,857 - INFO: Whisper 모델로 텍스트 변환 시작: /var/folders/9w/kjdpzhfn6hdb64q2httmjc1h0000gn/T/tmpkhnil9oi/sample_audio_normalized.wav\n",
      "/opt/anaconda3/envs/venv-keyword/lib/python3.8/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "2024-12-17 14:42:24,556 - INFO: 텍스트 변환 완료. 소요 시간: 22.69846487045288 초\n",
      "\n",
      "Unexpected Error: Error during script execution: /opt/anaconda3/envs/venv-keyword/lib/python3.8/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "2024-12-17 14:42:01,850 - INFO: WAV 변환 완료: /var/folders/9w/kjdpzhfn6hdb64q2httmjc1h0000gn/T/tmpkhnil9oi/sample_audio_converted.wav\n",
      "2024-12-17 14:42:01,857 - INFO: 오디오 정규화 완료: /var/folders/9w/kjdpzhfn6hdb64q2httmjc1h0000gn/T/tmpkhnil9oi/sample_audio_normalized.wav\n",
      "2024-12-17 14:42:01,857 - INFO: Whisper 모델로 텍스트 변환 시작: /var/folders/9w/kjdpzhfn6hdb64q2httmjc1h0000gn/T/tmpkhnil9oi/sample_audio_normalized.wav\n",
      "/opt/anaconda3/envs/venv-keyword/lib/python3.8/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n",
      "2024-12-17 14:42:24,556 - INFO: 텍스트 변환 완료. 소요 시간: 22.69846487045288 초\n",
      "\n",
      "Final result: FFmpeg converter path: /opt/homebrew/bin/ffmpeg\n",
      "FFprobe path: /opt/homebrew/bin/ffprobe\n",
      "Processing file: /tmp/sample_audio.webm\n",
      "\t\t 파일 길이: 46.695 초\n",
      "{'maf_idx': '1', 'voice_to_text': ' 안녕하세요 포항시 오천읍에 거주하는 이강일입니다.  저는 지난 11월 13일 이후로 집에서 나오는 수돗물에서 고약한 냄새가 나기 시작했습니다.  처음에는 아파트 물탱크에 문제가 있는 줄 알고 대수롭지 않게 여겼는데 냄새가 계속 나서 걱정이 돼서 신고합니다.  현재 수돗물에서 흙냄새와 곰팡이 냄새가 나고 그래서 설거지나 세수는 물론 물을 마실 수가 없습니다.  생수로 대체해서 사용하고 있는데 이 문제로 매우 불편을 겪고 있습니다.  포항시 수돗물 원수의 40%를 공급하는 경주 안개땜에서 녹조현상이 발생했다고 들었고 남조류에서 발생한 지오스민이 냄새를 유발한다고 합니다.  이 문제에 대한 빠른 대응을 부탁드립니다. 감사합니다.'}\n"
     ]
    }
   ],
   "source": [
    "maf_idx = 1\n",
    "file_path = '/home/yjtech/Desktop/LLM/sample_audio.webm'\n",
    "\n",
    "\n",
    "voice_datas = {'maf_idx': maf_idx, 'file_path': file_path}\n",
    "result = execute_on_mac(voice_datas['maf_idx'], voice_datas['file_path'])\n",
    "\n",
    "print(f\"Final result: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv38-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
