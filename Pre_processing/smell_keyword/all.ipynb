{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {\n",
    "    \"쓰레기 관련\": {\n",
    "        \"locations\": [\n",
    "            \"쓰레기 매립장\", \"쓰레기 처리장\", \"재활용 센터\", \"음식물 쓰레기장\", \"불법 폐기물 처리장\",\n",
    "            \"폐기물 소각장\", \"주변 골목길\", \"공동 주택 쓰레기장\", \"아파트 단지 쓰레기장\", \"학교 근처 쓰레기장\",\n",
    "            \"병원 쓰레기장\", \"공원 주변 쓰레기장\", \"도로변 쓰레기장\", \"지하철 역 주변\", \"대형마트 쓰레기장\",\n",
    "            \"버스 정류장 근처\", \"도시 외곽 쓰레기장\", \"항만 주변\", \"농촌 지역 쓰레기장\", \"도시 중심가 쓰레기장\",\n",
    "            \"포항시 북구\", \"포항시 남구\", \"포스코\", \"포항항\", \"포항대학교\",\n",
    "            \"포항 철강 산업단지\", \"포항 주변 해안\", \"포항시내\", \"포항 공원\", \"포항 해상\",\n",
    "            \"포항역\", \"포항 근처 산\", \"포항 해수욕장\", \"포항시 외곽\", \"포항 근처 도로\",\n",
    "            \"포항 남부 해안도로\", \"포항 북부 해안도로\", \"포항 근교 농촌\", \"포항 일대 농업지역\", \"포항 주요 광장\"\n",
    "        ],\n",
    "\n",
    "        \"smell_types\": [\n",
    "            \"악취\", \"화학 냄새\", \"부패한 냄새\", \"쓰레기 냄새\", \"찌든 냄새\", \"타는 냄새\", \"고약한 냄새\", \n",
    "            \"불쾌한 냄새\", \"탄 냄새\", \"침투성 냄새\", \"메스꺼운 냄새\", \"가스 냄새\", \"산성 냄새\", \"날카로운 냄새\", \n",
    "            \"오염된 냄새\", \"지속적으로 나는 냄새\", \"폭발적 악취\", \"썩은 물질 냄새\", \"퇴비 냄새\", \"더러운 냄새\"\n",
    "        ],\n",
    "\n",
    "        \"intensity_adjectives\": [\n",
    "            \"쾌쾌하게\", \"심하게\", \"지속적으로\", \"불쾌하게\", \"찌들게\", \"강하게\", \"독하게\", \"자극적으로\", \n",
    "            \"비린내처럼\", \"지독하게\", \"매캐하게\", \"묵직하게\", \"축축하게\", \"역하게\", \"찌르는 듯이\", \"강렬하게\", \n",
    "            \"폭발적으로\", \"극도로\", \"심각하게\", \"거슬리게\"\n",
    "        ],\n",
    "\n",
    "        \"issues\": [\n",
    "            \"쓰레기 처리 미비\", \"불법 투기된 폐기물\", \"재활용 분리수거 미흡\", \"음식물 쓰레기 악취\", \"폐기물 소각으로 인한 매연\", \n",
    "            \"쓰레기 적체\", \"쓰레기차 통행 불편\", \"폐기물 배출 지연\", \"유해 가스 발생\", \"불법 폐기물 매립\", \n",
    "            \"쓰레기통 부족\", \"도로에 쓰레기 방치\", \"재활용 품목 혼합\", \"쓰레기장 인근 불쾌한 냄새\", \"쓰레기 처리 불완전\", \n",
    "            \"도로에 쓰레기 던져짐\", \"소각장 연기 발생\", \"고장난 재활용 기계\", \"쓰레기통 불법 방치\", \"분리배출 혼잡\"\n",
    "        ],\n",
    "\n",
    "        \"departments\": [\n",
    "            \"환경 관리팀\", \"청소 관리팀\", \"재활용 관리팀\", \"폐기물 처리팀\", \"소각장 운영팀\", \"대기 관리팀\", \n",
    "            \"도시 재활용팀\", \"환경 안전팀\", \"교통 관리팀\", \"환경 연구팀\", \"자원 회수팀\", \"공공 서비스팀\", \n",
    "            \"청소 공공팀\", \"환경 감시팀\", \"기후 변화 대응팀\", \"시설 운영팀\", \"도시 환경 관리팀\", \"폐기물 분석팀\", \n",
    "            \"오염 물질 처리팀\", \"재활용 기술팀\"\n",
    "        ],\n",
    "\n",
    "        \"effects\": [\n",
    "            \"생활 불편\", \"호흡기 문제\", \"냄새로 인한 불쾌감\", \"알레르기 증상\", \"건강에 해로움\", \"환경 오염\", \n",
    "            \"시민 불만\", \"민원 발생\", \"주변 환경 개선 필요\", \"지역 이미지 훼손\", \"공공 안전 문제\", \"도시 미관 저하\", \n",
    "            \"공기 질 악화\", \"교통 혼잡\", \"관광지 방문 감소\", \"쾌적한 환경 저하\", \"수면 방해\", \"민원 처리 지연\", \n",
    "            \"공공서비스 감소\", \"경제적 손실\"\n",
    "        ],\n",
    "        \"time_of_day\": [\n",
    "            \"아침\", \"오전\", \"낮\", \"오후\", \"저녁\", \"밤\", \"새벽\",\n",
    "            \"오전 6시부터 7시\", \"오전 9시부터 10시\", \"오후 1시부터 2시\", \n",
    "            \"오후 3시부터 4시\", \"저녁 6시부터 7시\", \"밤 10시부터 11시\", \n",
    "            \"새벽 2시부터 3시\"\n",
    "        ]\n",
    "     },\n",
    "\n",
    "\n",
    "\n",
    "    \"날씨 관련\": {\n",
    "        \"locations\": [\n",
    "            \"포항시 북구\", \"포항시 남구\", \"포스코\", \"포항항\", \"포항대학교\",\n",
    "            \"포항 철강 산업단지\", \"포항 주변 해안\", \"포항시내\", \"포항 공원\", \"포항 해상\",\n",
    "            \"포항역\", \"포항 근처 산\", \"포항 해수욕장\", \"포항시 외곽\", \"포항 근처 도로\",\n",
    "            \"포항 남부 해안도로\", \"포항 북부 해안도로\", \"포항 근교 농촌\", \"포항 일대 농업지역\", \"포항 주요 광장\"\n",
    "        ],\n",
    "\n",
    "        \"smell_types\": [\n",
    "            \"산성 냄새\", \"습한 냄새\", \"상쾌한 냄새\", \"짙은 미세먼지\", \"소나기 후 냄새\",\n",
    "            \"염분이 섞인 냄새\", \"포근한 바람 냄새\", \"비 오는 날 냄새\", \"진한 해풍 냄새\", \"우박 냄새\",\n",
    "            \"장마철 냄새\", \"선선한 냄새\", \"습기 섞인 냄새\", \"더운 날씨의 냄새\", \"뿌연 공기\",\n",
    "            \"자연의 냄새\", \"먼지 냄새\", \"미세먼지 냄새\", \"구름 냄새\", \"비 온 후 냄새\"\n",
    "        ],\n",
    "\n",
    "        \"intensity_adjectives\": [\n",
    "            \"강하게\", \"약하게\", \"지속적으로\", \"급격하게\", \"급히\", \"덥게\", \"차갑게\", \"어두운\", \n",
    "            \"차츰\", \"가끔\", \"심하게\", \"낮게\", \"매우\", \"불규칙하게\", \"짧게\", \"긴 시간 동안\", \"폭발적으로\", \n",
    "            \"차분하게\", \"점차적으로\", \"습기 찬\"\n",
    "        ],\n",
    "\n",
    "        \"issues\": [\n",
    "            \"갑작스러운 비\", \"폭염\", \"대설\", \"장마\", \"강풍\", \"미세먼지\", \"안개\", \"강한 비바람\", \n",
    "            \"황사\", \"온도 급변\", \"건조한 날씨\", \"태풍\", \"기온 차이\", \"눈보라\", \"뇌우\", \"열대야\", \n",
    "            \"저기압\", \"고기압\", \"풍속 증가\", \"불안정한 날씨\"\n",
    "        ],\n",
    "\n",
    "\n",
    "        \"departments\": [\n",
    "            \"기상 예보팀\", \"기후 연구팀\", \"미세먼지 대책팀\", \"기상 안전팀\", \"기후 변화 대응팀\", \n",
    "            \"대기 관리팀\", \"기상 기술팀\", \"폭염 대책팀\", \"기상 정보 제공팀\", \"강수량 관리팀\", \n",
    "            \"기후 모델링 팀\", \"태풍 연구팀\", \"날씨 분석팀\", \"기상 측정팀\", \"온도 측정팀\", \"기상 해석팀\", \n",
    "            \"대기 오염 관리팀\", \"기상 데이터 분석팀\", \"산악 기상팀\", \"기후 변화 예측팀\"\n",
    "        ],\n",
    "\n",
    "        \"effects\": [\n",
    "            \"교통 혼잡\", \"건강 문제\", \"미세먼지 영향\", \"농작물 피해\", \"산불 위험\", \"대기 오염 증가\", \n",
    "            \"집중력 저하\", \"눈길 사고\", \"체온 조절 어려움\", \"습기 문제\", \"기상 난민 발생\", \"수확량 감소\", \n",
    "            \"기후 변화로 인한 생활 불편\", \"폭염으로 인한 탈진\", \"강풍으로 인한 시설 피해\", \"눈사태 발생\", \n",
    "            \"시민 불편\", \"야외 활동 제한\", \"소방 활동 어려움\", \"기상 예보 오류\"\n",
    "        ],\n",
    "        \"time_of_day\": [\n",
    "            \"아침\", \"오전\", \"낮\", \"오후\", \"저녁\", \"밤\", \"새벽\",\n",
    "            \"오전 6시부터 7시\", \"오전 9시부터 10시\", \"오후 1시부터 2시\", \n",
    "            \"오후 3시부터 4시\", \"저녁 6시부터 7시\", \"밤 10시부터 11시\", \n",
    "            \"새벽 2시부터 3시\"\n",
    "        ]\n",
    "     },\n",
    "\n",
    "\n",
    "    \"공장 관련\": {\n",
    "        \"locations\": [\n",
    "            \"화학 공장\", \"플라스틱 제조 공장\", \"폐수 처리 공장\", \"섬유 공장\", \"금속 가공 공장\",\n",
    "            \"자동차 부품 제조 공장\", \"전자 부품 공장\", \"석유 정제 공장\", \"시멘트 공장\", \"비료 공장\",\n",
    "            \"고무 공장\", \"제지 공장\", \"가구 제조 공장\", \"유리 공장\", \"주조 공장\",\n",
    "            \"플라스틱 가공 공장\", \"코팅 공장\", \"제약 공장\", \"화장품 제조 공장\", \"고체 연료 공장\",\n",
    "            \"전자 폐기물 처리 공장\", \"아스팔트 공장\", \"타이어 제조 공장\", \"도료 제조 공장\", \"농약 공장\",\n",
    "            \"음료 제조 공장\", \"고속 인쇄 공장\", \"전력 생산 공장\", \"스틸 가공 공장\", \"세제 제조 공장\",\n",
    "            \"복합 소재 제조 공장\", \"케이블 제조 공장\", \"냉각 기기 제조 공장\", \"반도체 공장\", \"방직 공장\",\n",
    "            \"폐기물 소각 공장\", \"세라믹 제조 공장\", \"폴리머 공장\", \"석탄 연료 공장\", \"합성수지 공장\"\n",
    "        ],\n",
    "        \"smell_types\": [\n",
    "            \"화학약품 냄새\", \"타는 냄새\", \"매운 냄새\", \"오염된 물 냄새\", \"기름 냄새\",\n",
    "            \"산성 냄새\", \"날카로운 냄새\", \"지속적인 냄새\", \"부식 냄새\", \"찌든 냄새\",\n",
    "            \"유기물 냄새\", \"불쾌한 냄새\", \"탄 냄새\", \"매캐한 냄새\", \"고약한 냄새\",\n",
    "            \"찌르는 냄새\", \"폭발적인 악취\", \"가스 냄새\", \"비린내\", \"혼합된 화학 냄새\",\n",
    "            \"플라스틱 녹는 냄새\", \"고무 타는 냄새\", \"독성 화학물 냄새\", \"미세 먼지 냄새\", \"금속성 냄새\",\n",
    "            \"염료 냄새\", \"공기 중의 찌든 냄새\", \"방부제 냄새\", \"부패 냄새\", \"미묘한 가스 냄새\",\n",
    "            \"강한 접착제 냄새\", \"분말 화학 냄새\", \"오존 냄새\", \"소각된 폐기물 냄새\", \"연소 냄새\"\n",
    "        ],\n",
    "        \"intensity_adjectives\": [\n",
    "            \"습하게\", \"축축하게\", \"뜨겁게\", \"서늘하게\", \"쾌쾌하게\",\n",
    "            \"지독하게\", \"자극적으로\", \"비릿하게\", \"무겁게\", \"매캐하게\",\n",
    "            \"강하게\", \"불쾌하게\", \"날카롭게\", \"침투성 있게\", \"섞인 듯이\",\n",
    "            \"지속적으로\", \"심하게\", \"뿌옇게\", \"잔뜩\", \"독하게\",\n",
    "            \"질식할 듯이\", \"스산하게\", \"뚜렷하게\", \"가득히\", \"찌르는 듯이\",\n",
    "            \"폭발적으로\", \"스며들 듯이\", \"거슬리게\", \"끈질기게\", \"오랫동안 남아있게\",\n",
    "            \"혼탁하게\", \"무겁고 답답하게\", \"강렬하게\", \"끈적하게\", \"날카롭게 퍼지게\"\n",
    "        ],\n",
    "        \"effects\": [\n",
    "            \"호흡이 어려움\", \"불쾌감\", \"피로감\", \"두통\", \"심한 자극\", \n",
    "            \"산소 부족\", \"기운이 떨어짐\", \"눈이 따끔거림\", \"집중력이 떨어짐\", \"숨쉬기 힘듦\",\n",
    "            \"어지럼증\", \"메스꺼움\", \"고통스러움\", \"불쾌한 기분\", \"화학물질로 인한 부작용\",\n",
    "            \"기계 소리로 인한 스트레스\", \"피부 자극\", \"호흡기 질환 유발\", \"불안감\", \"우울한 기분\"\n",
    "        ],\n",
    "        \"issues\": [\n",
    "            \"화학물질 유출\", \"공기 오염\", \"소음 문제\", \"산업 폐기물 처리 문제\", \"고온 방출 문제\", \n",
    "            \"화학 가스 누출\", \"폐수 방류\", \"타는 냄새 발생\", \"연기 발생\", \"불법 배출\",\n",
    "            \"불완전 연소\", \"가스 폭발 위험\", \"기계 고장\", \"부주의로 인한 사고\", \"공기 질 악화\",\n",
    "            \"소음 공해\", \"환경 파괴\", \"미세먼지 발생\", \"기계 오작동\", \"산업 재해\"\n",
    "        ],\n",
    "        \"departments\": [\n",
    "            \"환경 관리부\", \"안전 관리부\", \"시설 관리부\", \"기계 설비 부서\", \"전기 관리부\", \n",
    "            \"화학 부서\", \"폐기물 처리 부서\", \"사고 예방 부서\", \"노동 안전 부서\", \"품질 관리 부서\",\n",
    "            \"기술 부서\", \"연구개발 부서\", \"운영 부서\", \"제조 부서\", \"정비 부서\",\n",
    "            \"에너지 관리 부서\", \"운송 부서\", \"공정 관리 부서\", \"위험물 관리 부서\", \"프로젝트 관리 부서\"\n",
    "        ],\n",
    "        \"time_of_day\": [\n",
    "            \"아침\", \"오전\", \"낮\", \"오후\", \"저녁\", \"밤\", \"새벽\",\n",
    "            \"오전 6시부터 7시\", \"오전 9시부터 10시\", \"오후 1시부터 2시\", \n",
    "            \"오후 3시부터 4시\", \"저녁 6시부터 7시\", \"밤 10시부터 11시\", \n",
    "            \"새벽 2시부터 3시\"\n",
    "        ]\n",
    "     },\n",
    "    \n",
    "    \"축산 관련\": {\n",
    "        \"locations\": [\n",
    "            \"축사\", \"가축 사육장\", \"도살장\", \"젖소 농장\", \"돼지 농장\",\n",
    "            \"닭 농장\", \"가금류 농장\", \"양 농장\", \"산란계 농장\", \"육계 농장\",\n",
    "            \"소 사육장\", \"염소 농장\", \"오리 농장\", \"타조 농장\", \"사료 공장\",\n",
    "            \"가축 폐기물 처리장\", \"동물 보호소\", \"동물 실험 시설\", \"농업 단지\", \"대규모 축산 시설\",\n",
    "            \"우시장\", \"작은 동물 농장\", \"방목된 가축 사육지\", \"계란 생산 농장\", \"유제품 가공 공장\",\n",
    "            \"축산 폐수 처리장\", \"말 농장\", \"사슴 농장\", \"낙타 농장\", \"산림지 축산 단지\",\n",
    "            \"농촌 지역 축사\", \"가축 퇴비 저장소\", \"야생동물 보호 구역\", \"동물 사육 체험장\", \"생축 경매장\",\n",
    "            \"가축 운송 시설\", \"가축 질병 격리 시설\", \"고지대 목장\", \"호수 인근 축사\", \"냄새 민감 지역 축사\"\n",
    "        ],\n",
    "        \"smell_types\": [\n",
    "            \"악취\", \"분뇨 냄새\", \"동물 배설물 냄새\", \"소 똥 냄새\", \"돼지 똥 냄새\",\n",
    "            \"새우 배설물 냄새\", \"시큼한 냄새\", \"퇴비 냄새\", \"동물 사체 냄새\", \"음식물 냄새\",\n",
    "            \"동물의 땀 냄새\", \"단백질 냄새\", \"육류 냄새\", \"비린 냄새\", \"불쾌한 냄새\",\n",
    "            \"새끼 동물 냄새\", \"소화불량 냄새\", \"기름 냄새\", \"가축 사료 냄새\", \"발효된 냄새\",\n",
    "            \"침전된 물질 냄새\", \"동물 사료 냄새\", \"자극적인 냄새\", \"축산물 가공 냄새\", \"석회 냄새\"\n",
    "        ],\n",
    "        \"intensity_adjectives\": [\n",
    "            \"강하게\", \"지속적으로\", \"심하게\", \"불쾌하게\", \"역하게\", \n",
    "            \"찌들게\", \"매캐하게\", \"매우\", \"강렬하게\", \"매우 강하게\", \n",
    "            \"거세게\", \"자욱하게\", \"잔뜩\", \"지독하게\", \"짙게\", \n",
    "            \"심각하게\", \"스며들 듯이\", \"찬물에 푹 담근 듯이\", \"집요하게\", \"끈질기게\"\n",
    "        ],\n",
    "        \"effects\": [\n",
    "            \"호흡 곤란\", \"메스꺼움\", \"불쾌감\", \"피로감\", \"두통\", \n",
    "            \"기운이 빠짐\", \"눈 자극\", \"어지러움\", \"냄새로 인한 스트레스\", \"심한 자극\", \n",
    "            \"구역질\", \"기분 나쁨\", \"화학적 반응\", \"심한 불쾌감\", \"호흡기 질환\", \n",
    "            \"피부 자극\", \"산소 부족\", \"집중력 저하\", \"호흡기 알레르기\", \"불안감\"\n",
    "        ],\n",
    "        \"issues\": [\n",
    "            \"동물 배설물 처리 문제\", \"악취 발생\", \"환경 오염\", \"위생 문제\", \"사료 관리 문제\",\n",
    "            \"동물 건강 문제\", \"동물 도살 문제\", \"가축 질병 발생\", \"미세먼지 발생\", \"불법 축산물 유통\",\n",
    "            \"동물 학대 문제\", \"동물 복지 문제\", \"축산 폐기물 처리 문제\", \"소음 문제\", \"분뇨 유출\",\n",
    "            \"해충 문제\", \"하수도 문제\", \"악취와 건강 문제\", \"작물 오염\", \"가축 재배 문제\"\n",
    "        ],\n",
    "        \"departments\": [\n",
    "            \"환경 관리부\", \"농업 부서\", \"축산업 부서\", \"식품 위생 부서\", \"동물 관리 부서\", \n",
    "            \"사료 관리 부서\", \"농업 안전 부서\", \"위생 관리 부서\", \"농업 시설 관리 부서\", \"질병 관리 부서\", \n",
    "            \"동물 복지 부서\", \"농업 교육 부서\", \"환경 보호 부서\", \"농업 연구 부서\", \"농장 안전 부서\", \n",
    "            \"소음 및 악취 관리 부서\", \"농업 생산 부서\", \"폐기물 처리 부서\", \"축산업 기술 부서\", \"수의학 부서\"\n",
    "        ],\n",
    "        \"time_of_day\": [\n",
    "            \"아침\", \"오전\", \"낮\", \"오후\", \"저녁\", \"밤\", \"새벽\",\n",
    "            \"오전 6시부터 7시\", \"오전 9시부터 10시\", \"오후 1시부터 2시\", \n",
    "            \"오후 3시부터 4시\", \"저녁 6시부터 7시\", \"밤 10시부터 11시\", \n",
    "            \"새벽 2시부터 3시\"\n",
    "        ]\n",
    "     },\n",
    " \n",
    "    \"생활 악취 관련\": {\n",
    "        \"locations\": [\n",
    "            \"주택가\", \"아파트 단지\", \"공동 주택\", \"주차장\", \"상가 근처\", \n",
    "            \"학교 주변\", \"병원 주변\", \"도시 근교\", \"공원\", \"놀이터\", \n",
    "            \"버스 정류장\", \"지하철 역\", \"길거리\", \"대형마트\", \"택시 승강장\", \n",
    "            \"레스토랑 주변\", \"카페 근처\", \"도심지\", \"주택가 골목길\", \"공공 화장실\"\n",
    "        ],\n",
    "        \"smell_types\": [\n",
    "            \"악취\", \"음식물 냄새\", \"쓰레기 냄새\", \"하수구 냄새\", \"화학 냄새\", \n",
    "            \"배수구 냄새\", \"쓰레기통 냄새\", \"담배 냄새\", \"곰팡이 냄새\", \"사람 땀 냄새\", \n",
    "            \"동물 냄새\", \"오래된 냄새\", \"불쾌한 냄새\", \"자극적인 냄새\", \"타는 냄새\", \n",
    "            \"강한 냄새\", \"화장실 냄새\", \"음악 센터 냄새\", \"비린내\", \"가스 냄새\"\n",
    "        ],\n",
    "        \"intensity_adjectives\": [\n",
    "            \"쾌쾌하게\", \"심하게\", \"지속적으로\", \"불쾌하게\", \"찌들게\", \n",
    "            \"강하게\", \"독하게\", \"자극적으로\", \"비린내처럼\", \"지독하게\", \n",
    "            \"매캐하게\", \"묵직하게\", \"축축하게\", \"역하게\", \"찌르는 듯이\", \n",
    "            \"강렬하게\", \"폭발적으로\", \"극도로\", \"심각하게\", \"거슬리게\", \n",
    "            \"짙게\", \"스며들 듯이\", \"자욱하게\", \"묵은 듯이\", \"날카롭게\"\n",
    "        ],\n",
    "        \n",
    "        \"effects\": [\n",
    "            \"호흡 곤란\", \"메스꺼움\", \"불쾌감\", \"피로감\", \"두통\", \n",
    "            \"기운이 빠짐\", \"눈 자극\", \"어지러움\", \"냄새로 인한 스트레스\", \n",
    "            \"심한 자극\", \"구역질\", \"기분 나쁨\", \"화학적 반응\", \"심한 불쾌감\", \n",
    "            \"호흡기 질환\", \"피부 자극\", \"산소 부족\", \"집중력 저하\", \"호흡기 알레르기\", \n",
    "            \"불안감\"\n",
    "    \t],\n",
    "\n",
    "        \"issues\": [\n",
    "            \"냄새로 인한 생활 불편\", \"주민 건강에 미치는 영향\", \"주민 불만 증가\", \n",
    "            \"공기 질 저하\", \"불쾌한 환경\", \"심각한 생활 환경 문제\", \"청결 부족\", \n",
    "            \"위생 상태 문제\", \"불쾌한 공기\", \"악취 배출 통제 문제\", \"환경 오염\", \n",
    "            \"냄새로 인한 스트레스\", \"심각한 공공 문제\", \"일상 생활 불편\", \n",
    "            \"집안 환경의 악취\", \"사회적 불편\", \"소음과 냄새의 복합적 문제\", \"냄새 민감도 증가\"\n",
    "        ],\n",
    "        \"departments\": [\n",
    "            \"환경부\", \"보건복지부\", \"지자체 환경 부서\", \"시청 환경 관리 부서\", \n",
    "            \"주택 관리 부서\", \"상수도 관리 부서\", \"도시 관리 부서\", \n",
    "            \"보건소\", \"지역 환경 협의체\", \"위생 관리 부서\", \"공공건물 관리 부서\", \n",
    "            \"지자체 보건 부서\", \"하수도 관리 부서\", \"교통부\", \"민원센터\", \n",
    "            \"주차장 관리 부서\", \"상가 관리 부서\", \"도시 재개발 부서\", \n",
    "            \"환경정화 부서\", \"공공서비스 부서\"\n",
    "        ],\n",
    "        \"time_of_day\": [\n",
    "            \"아침\", \"오전\", \"낮\", \"오후\", \"저녁\", \"밤\", \"새벽\",\n",
    "            \"오전 6시부터 7시\", \"오전 9시부터 10시\", \"오후 1시부터 2시\", \n",
    "            \"오후 3시부터 4시\", \"저녁 6시부터 7시\", \"밤 10시부터 11시\", \n",
    "            \"새벽 2시부터 3시\"\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    \"건설현장 관련\": {\n",
    "        \"locations\": [\n",
    "            \"주택 공사 현장\", \"상업용 건물 공사 현장\", \"도로 건설 현장\", \"다리 건설 현장\", \n",
    "            \"철도 건설 현장\", \"지하철 공사 현장\", \"도시 재개발 현장\", \"고속도로 공사 현장\", \n",
    "            \"기반 시설 공사 현장\", \"상하수도 공사 현장\", \"아파트 단지 건설 현장\", \n",
    "            \"상가 및 빌딩 건설 현장\", \"학교 건설 현장\", \"병원 건설 현장\", \"공장 건설 현장\", \n",
    "            \"터널 건설 현장\", \"산업단지 건설 현장\", \"고층 건물 공사 현장\", \"주차장 건설 현장\", \n",
    "            \"공항 건설 현장\"\n",
    "        ],\n",
    "        \"smell_types\": [\n",
    "            \"시멘트 냄새\", \"타는 냄새\", \"화학 물질 냄새\", \"아스팔트 냄새\", \"석유 냄새\", \n",
    "            \"배관 설치 냄새\", \"청소 화학 냄새\", \"페인트 냄새\", \"솔벤트 냄새\", \"금속 냄새\", \n",
    "            \"붕괴된 건축물 냄새\", \"조합 재료 냄새\", \"비산 먼지 냄새\", \"기계 오일 냄새\", \n",
    "            \"유해 화학물질 냄새\", \"기계 연료 냄새\", \"시멘트 분말 냄새\", \"섬유 화학 냄새\", \n",
    "            \"건설 자재 냄새\", \"유리 및 플라스틱 재료 냄새\"\n",
    "        ],\n",
    "        \"intensity_adjectives\": [\n",
    "            \"강하게\", \"지속적으로\", \"심하게\", \"자욱하게\", \"불쾌하게\", \n",
    "            \"심각하게\", \"매캐하게\", \"화학적으로\", \"묵직하게\", \"자극적으로\", \n",
    "            \"독하게\", \"지독하게\", \"폭발적으로\", \"강렬하게\", \"비산성으로\", \n",
    "            \"눈에 띄게\", \"빈번하게\", \"거슬리게\", \"질식할 정도로\", \"짙게\"\n",
    "        ],\n",
    "        \"effects\": [\n",
    "            \"호흡 곤란\", \"눈 자극\", \"피로감\", \"어지러움\", \"불쾌감\", \n",
    "            \"기침\", \"두통\", \"기운이 빠짐\", \"화학적 반응\", \"호흡기 질환\", \n",
    "            \"피부 자극\", \"집중력 저하\", \"스트레스\", \"심리적 불편\", \"소음으로 인한 스트레스\"\n",
    "   \t\t],\n",
    "        \"issues\": [\n",
    "            \"주변 주민 불편\", \"건설 근로자의 건강 문제\", \"대기 오염\", \"화학물질 유출\", \n",
    "            \"공사로 인한 소음과 악취\", \"공공 건강 위협\", \"도로 교통 문제\", \"공기 질 저하\", \n",
    "            \"근로자 안전 문제\", \"주거지 근처 건설 현장\", \"주차 공간 부족\", \"지속적인 냄새 문제\", \n",
    "            \"구조물 붕괴 위험\", \"지속적인 공사 소음\", \"공사 진행 중 환경 오염\", \"화학 물질 누출 위험\", \n",
    "            \"시멘트 먼지 문제\", \"불완전한 작업 환경\", \"비효율적인 건설 작업\", \"작업 환경으로 인한 스트레스\"\n",
    "        ],\n",
    "        \"departments\": [\n",
    "            \"건설부\", \"환경부\", \"시청 건설 관리 부서\", \"안전 관리 부서\", \"환경 오염 관리 부서\", \n",
    "            \"공공 안전 부서\", \"건설 현장 관리 부서\", \"위험 관리 부서\", \"주택 관리 부서\", \n",
    "            \"도로 공사 관리 부서\", \"교통 관리 부서\", \"지자체 환경 관리 부서\", \"위생 관리 부서\", \n",
    "            \"재활용 및 폐기물 관리 부서\", \"시설 공사 관리 부서\", \"시설 안전 부서\", \n",
    "            \"노동부\", \"보건소\", \"건설 근로자 안전 부서\", \"공공 서비스 부서\"\n",
    "        ],\n",
    "        \"time_of_day\": [\n",
    "            \"아침\", \"오전\", \"낮\", \"오후\", \"저녁\", \"밤\", \"새벽\",\n",
    "            \"오전 6시부터 7시\", \"오전 9시부터 10시\", \"오후 1시부터 2시\", \n",
    "            \"오후 3시부터 4시\", \"저녁 6시부터 7시\", \"밤 10시부터 11시\", \n",
    "            \"새벽 2시부터 3시\"\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from konlpy.tag import Mecab\n",
    "\n",
    "# mecab = Mecab()\n",
    "\n",
    "# def extract_dynamic_keywords(text, category):\n",
    "#     \"\"\"\n",
    "#     문장에서 카테고리 정보를 기반으로 키워드 추출.\n",
    "#     복합명사 처리 추가.\n",
    "#     \"\"\"\n",
    "#     # 형태소 분석\n",
    "#     pos_tags = mecab.pos(text)\n",
    "#     extracted_keywords = [word for word, tag in pos_tags if tag in [\"NNG\", \"NNP\"]]\n",
    "\n",
    "#     # 카테고리에서 복합 키워드 찾기\n",
    "#     category_keywords = (\n",
    "#         categories[category][\"locations\"] +\n",
    "#         categories[category][\"smell_types\"] +\n",
    "#         categories[category][\"intensity_adjectives\"]\n",
    "#     )\n",
    "\n",
    "#     # 복합 키워드 처리\n",
    "#     combined_keywords = []\n",
    "#     skip = False\n",
    "#     for i in range(len(extracted_keywords) - 1):\n",
    "#         if skip:\n",
    "#             skip = False\n",
    "#             continue\n",
    "#         current = extracted_keywords[i]\n",
    "#         next_word = extracted_keywords[i + 1]\n",
    "#         combined = f\"{current} {next_word}\"\n",
    "#         if combined in category_keywords:\n",
    "#             combined_keywords.append(combined)\n",
    "#             skip = True\n",
    "#         else:\n",
    "#             combined_keywords.append(current)\n",
    "    \n",
    "#     # 마지막 단어 추가\n",
    "#     if not skip:\n",
    "#         combined_keywords.append(extracted_keywords[-1])\n",
    "    \n",
    "#     # 문장 길이에 따라 동적 키워드 수 결정\n",
    "#     total_words = len(pos_tags)\n",
    "#     num_keywords = max(1, int(total_words * 0.5))\n",
    "#     return combined_keywords[:num_keywords]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_keywords_by_space(text, category):\n",
    "#     \"\"\"\n",
    "#     띄어쓰기를 기준으로 복합 키워드를 추출하며 조사를 제거.\n",
    "#     \"\"\"\n",
    "#     import re\n",
    "\n",
    "#     # 문장을 띄어쓰기 기준으로 분리\n",
    "#     words = text.split()\n",
    "\n",
    "#     # 조사 목록 (필요에 따라 추가)\n",
    "#     particles = [\"에서\", \"으로\", \"에\", \"의\", \"을\", \"를\", \"이\", \"가\", \"과\", \"와\", \"도\", \"는\", \"다\", \"만\"]\n",
    "\n",
    "#     # 단어에서 조사를 제거\n",
    "#     def remove_particle(word):\n",
    "#         for particle in particles:\n",
    "#             if word.endswith(particle):\n",
    "#                 return re.sub(f\"{particle}$\", \"\", word)  # 조사 제거\n",
    "#         return word\n",
    "\n",
    "#     # 카테고리 키워드 목록 (집합으로 변환)\n",
    "#     category_keywords = set(\n",
    "#         categories[category][\"locations\"] +\n",
    "#         categories[category][\"smell_types\"] +\n",
    "#         categories[category][\"intensity_adjectives\"]\n",
    "#     )\n",
    "\n",
    "#     # 복합 키워드 처리\n",
    "#     final_keywords = []\n",
    "#     temp_combination = []\n",
    "\n",
    "#     i = 0\n",
    "#     while i < len(words):\n",
    "#         clean_word = remove_particle(words[i])  # 단어에서 조사 제거\n",
    "#         temp_combination.append(clean_word)  # 단어 추가\n",
    "#         combined = \" \".join(temp_combination)  # 결합된 문자열 생성\n",
    "\n",
    "#         if combined in category_keywords:  # 결합 결과가 정확히 일치하면\n",
    "#             final_keywords.append(combined)  # 키워드로 저장\n",
    "#             temp_combination = []  # 임시 결합 초기화\n",
    "#         elif i == len(words) - 1:  # 마지막 단어 처리\n",
    "#             # temp_combination이 키워드와 매칭되지 않으면 버림\n",
    "#             temp_combination = []  # 초기화\n",
    "#         i += 1  # 다음 단어로 이동\n",
    "\n",
    "#     return final_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "citizen_greeting_templates = [\n",
    "\t\"여보세요?\",\n",
    "\t\"안녕하세요?\",\n",
    "\t\"저희 {location}에서 {issue} 관련하여 연락드렸습니다.\",\n",
    "\t\"안녕하세요. {location}에서 전화드렸습니다.\",\n",
    "\t\"여보세요? {location}의 {issue}에 대해 문의 드립니다.\",\n",
    "\t\"저희 {location}에서 {smell_type} 문제로 연락드렸습니다.\",\n",
    "\t\"안녕하세요. {location}에서 발생한 {issue} 문제에 대해 문의 드립니다.\"\n",
    "]\n",
    "\n",
    "agent_greeting_templates = [\n",
    "\t\"네, 민원센터입니다.\",\n",
    "\t\"네, {location}의 {department}입니다. 어떤 문제로 연락주셨나요?\",\n",
    "\t\"네, {location}에서 발생한 문제에 대해 상담 드리겠습니다.\",\n",
    "\t\"안녕하세요, {department}입니다. 무엇을 도와드릴까요?\",\n",
    "\t\"감사합니다, {department}입니다. 어떻게 도와드릴까요?\",\n",
    "\t\"안녕하세요. 무엇을 도와드릴 수 있을까요?\",\n",
    "\t\"네, {location}의 문제에 대해 확인하겠습니다.\"\n",
    "]\n",
    "\n",
    "citizen_complaint_templates = [\n",
    "\t\"저희 {location}에서 {smell_type}이 {intensity_adjective} 나고 있습니다. {effect}\",\n",
    "\t\"최근 {location}에서 {issue}로 불편을 겪고 있습니다. {effect}\",\n",
    "\t\"{location}에서 {smell_type}으로 인해 {effect} 문제가 발생하고 있습니다.\",\n",
    "\t\"저희 {location}에서 {smell_type}이 {intensity_adjective} 나고 있어 {effect}로 불편을 겪고 있습니다.\",\n",
    "\t\"저희 {location}에서 {issue}로 인해 심각한 불편을 겪고 있습니다. {effect}\",\n",
    "\t\"{location}에서 {smell_type} 때문에 {effect}가 발생하고 있습니다.\",\n",
    "\t\"최근 {location}에서 {smell_type}이 {intensity_adjective} 나고 있어 {effect}로 큰 불편을 겪고 있습니다.\",\n",
    "\t\"{location}에서 {smell_type}이 {intensity_adjective} 나고 있으며, {effect}로 생활에 불편이 많습니다.\",\n",
    "\t\"{location}에서 발생한 {issue}로 인해 {effect}로 불편함을 겪고 있습니다.\",\n",
    "\t\"{location}에서 {smell_type} 때문에 {effect} 문제가 발생하고 있습니다.\",\n",
    "\t\n",
    "\t\"저희 {location}에서 {time_of_day}에 {smell_type}이 {intensity_adjective} 나고 있어 {effect} 발생 중입니다.\",\n",
    "\t\"최근 {location}에서 {time_of_day}에 {issue}로 심각한 불편을 겪고 있습니다. {effect}\",\n",
    "\t\"{location}에서 {time_of_day}에 발생한 {smell_type} 때문에 {effect} 문제가 발생하고 있습니다.\",\n",
    "\t\"저희 {location}에서 {time_of_day}에 {issue}로 큰 불편을 겪고 있습니다. {effect}\",\n",
    "\t\"{location}에서 {time_of_day}에 {smell_type}이 {intensity_adjective} 나고 있어 {effect}로 매우 불편합니다.\"\n",
    "]\n",
    "\n",
    "agent_response_templates = [\n",
    "\t\"불편을 드려 대단히 죄송합니다. {effect} 해결을 위해 {location}에 대한 현장 점검을 실시하겠습니다. 잠시만 기다려 주시겠습니까?\",\n",
    "\t\"해당 문제를 해결하기 위해 최선을 다하겠습니다. 조치를 취할 수 있도록 {location}을 빠르게 점검하겠습니다.\",\n",
    "\t\"죄송합니다. {location}에서 발생한 문제에 대해 조치를 취하고 있습니다. 조금만 기다려 주세요.\",\n",
    "\t\"불편을 드려 정말 죄송합니다. {effect} 해결을 위해 신속히 대응하겠습니다.\",\n",
    "\t\"현재 {location}에 대한 점검을 시작하여 문제를 해결하겠습니다. 잠시만 기다려 주세요.\",\n",
    "\t\"문제를 해결하기 위해 최선을 다하겠습니다. 현장 점검 후 즉시 조치하겠습니다.\",\n",
    "\t\"불편을 드려 대단히 죄송합니다. 문제를 해결하기 위해 {location}을 점검하겠습니다.\",\n",
    "\t\"문제를 즉시 해결할 수 있도록 {location}에 대한 점검을 진행하겠습니다. 조금만 기다려 주세요.\",\n",
    "\t\"불편을 드려 대단히 죄송합니다. 해당 문제에 대해 최선의 조치를 취할 것입니다.\",\n",
    "\t\"죄송합니다. {location}에서 발생한 문제를 해결하기 위해 현장 점검을 진행하겠습니다.\",\n",
    "\t\n",
    "\t\"불편을 드려 대단히 죄송합니다. {time_of_day}에 발생한 {issue} 문제를 해결하기 위해 {location}에 대한 점검을 실시하겠습니다.\",\n",
    "\t\"현재 {location}에서 발생한 {issue} 문제에 대해 조치 중입니다. {time_of_day}에 완료될 예정입니다.\",\n",
    "\t\"죄송합니다. {time_of_day}에 {location}에서 발생한 문제를 해결하기 위해 신속히 대응하고 있습니다.\",\n",
    "\t\"불편을 드려 정말 죄송합니다. {time_of_day}에 발생한 {effect} 문제를 해결하기 위해 현장 점검을 진행 중입니다.\",\n",
    "\t\"{location}에서 발생한 {issue} 문제에 대해 {time_of_day}에 즉시 점검을 시작하겠습니다.\"\n",
    "]\n",
    "\n",
    "citizen_response_templates = [\n",
    "\t\"네, 그러니 빨리 좀 처리해주세요.\",\n",
    "\t\"그럼 신속히 해결해주세요.\",\n",
    "\t\"알겠습니다. 빠른 처리 부탁드립니다.\",\n",
    "\t\"네, 확인해 주세요. 빠른 해결을 바랍니다.\",\n",
    "\t\"알겠습니다. 최대한 빨리 처리해 주세요.\",\n",
    "\t\"그럼 문제를 빨리 해결해 주세요.\",\n",
    "\t\"네, 기다리겠습니다. 빨리 처리해 주세요.\",\n",
    "\t\"그럼 빠르게 해결해 주세요.\",\n",
    "\t\"알겠습니다. 처리 좀 해주세요.\",\n",
    "\t\"네, 처리가 되도록 부탁드립니다.\"\n",
    "]\n",
    "\n",
    "agent_acknowledge_templates = [\n",
    "\t\"네, 알겠습니다.\",\n",
    "\t\"확인 후 조치를 취하겠습니다.\",\n",
    "\t\"즉시 처리하겠습니다. 조금만 기다려 주세요.\",\n",
    "\t\"빠르게 조치를 취하겠습니다. 감사합니다.\",\n",
    "\t\"네, 확인 후 바로 처리하겠습니다.\",\n",
    "\t\"확인 후 처리하도록 하겠습니다.\",\n",
    "\t\"네, 바로 조치를 취하겠습니다.\",\n",
    "\t\"확인해 보고 빠르게 처리하겠습니다.\",\n",
    "\t\"알겠습니다. 최대한 빠르게 처리하겠습니다.\",\n",
    "\t\"네, 신속하게 처리하겠습니다.\"\n",
    "]\n",
    "\n",
    "citizen_farewell_templates = [\n",
    "\t\"수고하세요.\",\n",
    "\t\"감사합니다.\",\n",
    "\t\"좋은 하루 되세요.\",\n",
    "\t\"빠른 처리 감사합니다.\",\n",
    "\t\"수고 많으십니다.\",\n",
    "\t\"잘 부탁드립니다.\",\n",
    "\t\"고맙습니다.\",\n",
    "\t\"감사합니다. 처리 잘 부탁드립니다.\",\n",
    "\t\"수고하셨습니다.\",\n",
    "\t\"감사합니다. 좋은 하루 되세요.\"\n",
    "]\n",
    "\n",
    "agent_farewell_templates = [\n",
    "\t\"네, 감사합니다.\",\n",
    "\t\"저희가 도와드리겠습니다. 감사합니다.\",\n",
    "\t\"언제든지 연락 주세요. 감사합니다.\",\n",
    "\t\"감사합니다. 빠르게 처리하겠습니다.\",\n",
    "\t\"네, 처리 후 다시 연락드리겠습니다. 감사합니다.\",\n",
    "\t\"네, 감사합니다. 좋은 하루 되세요.\",\n",
    "\t\"저희가 도와드릴 수 있어 기쁩니다. 감사합니다.\",\n",
    "\t\"언제든지 연락주세요. 감사합니다.\",\n",
    "\t\"네, 처리 후 다시 연락드리겠습니다. 감사합니다.\",\n",
    "\t\"감사합니다. 좋은 하루 되세요.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "\n",
    "def generate_phone_conversation(location, issue, company_name, department, smell_type, intensity_adjective, effect, time_of_day):\n",
    "    citizen_greeting = random.choice(citizen_greeting_templates).format(location=location, issue=issue, company_name=company_name, smell_type=smell_type, department=department)\n",
    "    agent_greeting = random.choice(agent_greeting_templates).format(location=location, department=department, company_name=company_name)\n",
    "    citizen_complaint = random.choice(citizen_complaint_templates).format(location=location, smell_type=smell_type, intensity_adjective=intensity_adjective, effect=effect, issue=issue, time_of_day=time_of_day)\n",
    "    agent_response = random.choice(agent_response_templates).format(location=location, effect=effect, time_of_day=time_of_day, issue=issue)\n",
    "    citizen_response = random.choice(citizen_response_templates)\n",
    "    agent_acknowledge = random.choice(agent_acknowledge_templates)\n",
    "    citizen_farewell = random.choice(citizen_farewell_templates)\n",
    "    agent_farewell = random.choice(agent_farewell_templates)\n",
    "    \n",
    "    conversation = f\"{citizen_greeting} {agent_greeting} {citizen_complaint} {agent_response} {citizen_response} {agent_acknowledge} {citizen_farewell} {agent_farewell}\"\"담당자: {agent_farewell}\"\n",
    "    \n",
    "    return conversation\n",
    "\n",
    "\n",
    "def generate_all_combinations(category):\n",
    "    combinations = product(\n",
    "        categories[category][\"locations\"],\n",
    "        categories[category][\"issues\"],\n",
    "        categories[category][\"company_names\"],\n",
    "        categories[category][\"departments\"],\n",
    "        categories[category][\"smell_types\"],\n",
    "        categories[category][\"intensity_adjectives\"],\n",
    "        categories[category][\"effects\"],\n",
    "        categories[category][\"time_of_day\"]\n",
    "    )\n",
    "\n",
    "    complaints = []\n",
    "    for location, issue, company_name, department, smell_type, intensity_adjective, effect, time_of_day in tqdm(combinations):\n",
    "        \n",
    "        text = generate_phone_conversation(\n",
    "\t\t\tlocation=location,\n",
    "\t\t\tissue=issue,\n",
    "\t\t\tcompany_name=company_name,\n",
    "\t\t\tdepartment=department,\n",
    "\t\t\tsmell_type=smell_type,\n",
    "\t\t\tintensity_adjective=intensity_adjective,\n",
    "\t\t\teffect=effect,\n",
    "\t\t\ttime_of_day= time_of_day\n",
    "\t\t)\n",
    "        \n",
    "        keywords = [location, smell_type, time_of_day]\n",
    "        complaints.append({\"category\": category, \"text\": text, \"keywords\": keywords})\n",
    "    return complaints\n",
    "\n",
    "def generate_all_data():\n",
    "    \"\"\"모든 카테고리에서 데이터를 생성\"\"\"\n",
    "    data = []\n",
    "    for category in categories:\n",
    "        data.extend(generate_all_combinations(category))  # 모든 조합 생성\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "904400it [00:02, 350359.30it/s]\n",
      "756000it [00:00, 835656.79it/s]\n",
      "980000it [00:01, 837199.05it/s]\n",
      "720000it [00:02, 273361.23it/s]\n",
      "857500it [00:01, 834905.44it/s]\n",
      "980000it [00:03, 290587.76it/s]\n",
      "980000it [00:01, 837216.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋이 저장되었습니다: /home/yjtech2/Desktop/yurim/LLM/Data/smell_keyword/smell_keyword_train.json\n",
      "샘플 데이터: {'category': '쓰레기 관련', 'text': '오전에 쓰레기 매립장 주변을 지나갔는데 악취가 쾌쾌하게 심하게 났습니다. 이로 인해 주민들의 일상생활에 심각한 지장을 초래하고 있으며, 특히 아이들과 노약자들의 건강이 우려됩니다.', 'keywords': ['쓰레기 매립장', '악취', '쾌쾌하게']}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data = generate_all_data()\n",
    "final_output = {\n",
    "    \"data\": data\n",
    "}\n",
    "output_file = \"/home/yjtech2/Desktop/yurim/LLM/Data/smell_keyword/smell_keyword_train.json\"\n",
    "\n",
    "\n",
    "# JSON 저장\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_output, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"데이터셋이 저장되었습니다: {output_file}\")\n",
    "print(f\"샘플 데이터: {data[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>쓰레기 관련</td>\n",
       "      <td>이로 인해 주민들의 일상생활에 심각한 지장을 초래하고 있으며, 특히 아이들과 노약자...</td>\n",
       "      <td>[쓰레기 매립장, 악취, 쾌쾌하게]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>쓰레기 관련</td>\n",
       "      <td>쓰레기 매립장에서 악취가 쾌쾌하게 발생하고 있습니다. 이는 주변 환경을 심각하게 오...</td>\n",
       "      <td>[쓰레기 매립장, 악취, 쾌쾌하게]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>쓰레기 관련</td>\n",
       "      <td>쓰레기 매립장에서 악취가 쾌쾌하게 발생하고 있습니다. 이로 인해 주민들이 극심한 불...</td>\n",
       "      <td>[쓰레기 매립장, 악취, 쾌쾌하게]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>쓰레기 관련</td>\n",
       "      <td>이 문제로 인해 지역 주민들이 강력하게 항의하고 있습니다. 쓰레기 매립장에서 악취가...</td>\n",
       "      <td>[쓰레기 매립장, 악취, 쾌쾌하게]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>쓰레기 관련</td>\n",
       "      <td>쓰레기 매립장 주변에서 악취가 쾌쾌하게 상태로 보고되었습니다. 주변의 자연 생태계까...</td>\n",
       "      <td>[쓰레기 매립장, 악취, 쾌쾌하게]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6177895</th>\n",
       "      <td>건설현장 관련</td>\n",
       "      <td>방음벽 공사 현장 주변에서 연소된 화학물 냄새가 조용히 스며들게 상태로 보고되었습니...</td>\n",
       "      <td>[방음벽 공사 현장, 연소된 화학물 냄새, 조용히 스며들게]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6177896</th>\n",
       "      <td>건설현장 관련</td>\n",
       "      <td>방음벽 공사 현장에 연소된 화학물 냄새가 조용히 스며들게 발생 중이며, 냄새와 먼지...</td>\n",
       "      <td>[방음벽 공사 현장, 연소된 화학물 냄새, 조용히 스며들게]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6177897</th>\n",
       "      <td>건설현장 관련</td>\n",
       "      <td>연소된 화학물 냄새로 인해 방음벽 공사 현장에서 조용히 스며들게 문제가 보고되었습니...</td>\n",
       "      <td>[방음벽 공사 현장, 연소된 화학물 냄새, 조용히 스며들게]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6177898</th>\n",
       "      <td>건설현장 관련</td>\n",
       "      <td>방음벽 공사 현장 주변에서 연소된 화학물 냄새가 조용히 스며들게 상태로 보고되었습니...</td>\n",
       "      <td>[방음벽 공사 현장, 연소된 화학물 냄새, 조용히 스며들게]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6177899</th>\n",
       "      <td>건설현장 관련</td>\n",
       "      <td>방음벽 공사 현장 주변에서 연소된 화학물 냄새가 조용히 스며들게 상태로 보고되었습니...</td>\n",
       "      <td>[방음벽 공사 현장, 연소된 화학물 냄새, 조용히 스며들게]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6177900 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        category                                               text  \\\n",
       "0         쓰레기 관련  이로 인해 주민들의 일상생활에 심각한 지장을 초래하고 있으며, 특히 아이들과 노약자...   \n",
       "1         쓰레기 관련  쓰레기 매립장에서 악취가 쾌쾌하게 발생하고 있습니다. 이는 주변 환경을 심각하게 오...   \n",
       "2         쓰레기 관련  쓰레기 매립장에서 악취가 쾌쾌하게 발생하고 있습니다. 이로 인해 주민들이 극심한 불...   \n",
       "3         쓰레기 관련  이 문제로 인해 지역 주민들이 강력하게 항의하고 있습니다. 쓰레기 매립장에서 악취가...   \n",
       "4         쓰레기 관련  쓰레기 매립장 주변에서 악취가 쾌쾌하게 상태로 보고되었습니다. 주변의 자연 생태계까...   \n",
       "...          ...                                                ...   \n",
       "6177895  건설현장 관련  방음벽 공사 현장 주변에서 연소된 화학물 냄새가 조용히 스며들게 상태로 보고되었습니...   \n",
       "6177896  건설현장 관련  방음벽 공사 현장에 연소된 화학물 냄새가 조용히 스며들게 발생 중이며, 냄새와 먼지...   \n",
       "6177897  건설현장 관련  연소된 화학물 냄새로 인해 방음벽 공사 현장에서 조용히 스며들게 문제가 보고되었습니...   \n",
       "6177898  건설현장 관련  방음벽 공사 현장 주변에서 연소된 화학물 냄새가 조용히 스며들게 상태로 보고되었습니...   \n",
       "6177899  건설현장 관련  방음벽 공사 현장 주변에서 연소된 화학물 냄새가 조용히 스며들게 상태로 보고되었습니...   \n",
       "\n",
       "                                  keywords  \n",
       "0                      [쓰레기 매립장, 악취, 쾌쾌하게]  \n",
       "1                      [쓰레기 매립장, 악취, 쾌쾌하게]  \n",
       "2                      [쓰레기 매립장, 악취, 쾌쾌하게]  \n",
       "3                      [쓰레기 매립장, 악취, 쾌쾌하게]  \n",
       "4                      [쓰레기 매립장, 악취, 쾌쾌하게]  \n",
       "...                                    ...  \n",
       "6177895  [방음벽 공사 현장, 연소된 화학물 냄새, 조용히 스며들게]  \n",
       "6177896  [방음벽 공사 현장, 연소된 화학물 냄새, 조용히 스며들게]  \n",
       "6177897  [방음벽 공사 현장, 연소된 화학물 냄새, 조용히 스며들게]  \n",
       "6177898  [방음벽 공사 현장, 연소된 화학물 냄새, 조용히 스며들게]  \n",
       "6177899  [방음벽 공사 현장, 연소된 화학물 냄새, 조용히 스며들게]  \n",
       "\n",
       "[6177900 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "a = pd.DataFrame(data)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'쓰레기 매립장에서 매캐한 냄새가 강압적으로 발생하고 있습니다. 이 문제로 인해 주변 부동산 가격이 하락하고 있습니다'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.iloc[14851, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6177900 entries, 0 to 6177899\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Dtype \n",
      "---  ------    ----- \n",
      " 0   text      object\n",
      " 1   keywords  object\n",
      "dtypes: object(2)\n",
      "memory usage: 94.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    JSON 데이터를 불러와 Pandas DataFrame으로 변환\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        json_data = json.load(f)\n",
    "        \n",
    "    data = []\n",
    "    for item in json_data['data']:\n",
    "        if 'text' in item and 'keywords' in item:\n",
    "            data.append({\n",
    "                'text': item['text'],\n",
    "                'keywords': item['keywords']\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    print(df.info())\n",
    "    # None 값을 빈 문자열로 대체\n",
    "    df = df.fillna('')\n",
    "    return df\n",
    "\n",
    "\n",
    "# JSON 파일 경로\n",
    "file_path_train = \"/home/yjtech2/Desktop/yurim/LLM/Data/smell_keyword/smell_keyword_train.json\"\n",
    "df = load_data(file_path_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>쓰레기 매립장에서 악취가 쾌쾌하게 발생하고 있습니다. 이로 인해 주민들의 일상생활에...</td>\n",
       "      <td>[쓰레기 매립장, 악취, 쾌쾌하게]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>쓰레기 매립장에서 악취가 쾌쾌하게 발생하고 있습니다. 이는 주변 환경을 심각하게 오...</td>\n",
       "      <td>[쓰레기 매립장, 악취, 쾌쾌하게]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>쓰레기 매립장에서 악취가 쾌쾌하게 발생하고 있습니다. 이로 인해 주민들이 극심한 불...</td>\n",
       "      <td>[쓰레기 매립장, 악취, 쾌쾌하게]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>쓰레기 매립장에서 악취가 쾌쾌하게 발생하고 있습니다. 이 문제로 인해 지역 주민들이...</td>\n",
       "      <td>[쓰레기 매립장, 악취, 쾌쾌하게]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>쓰레기 매립장에서 악취가 쾌쾌하게 발생하고 있습니다. 주변의 자연 생태계까지 악영향...</td>\n",
       "      <td>[쓰레기 매립장, 악취, 쾌쾌하게]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text             keywords\n",
       "0  쓰레기 매립장에서 악취가 쾌쾌하게 발생하고 있습니다. 이로 인해 주민들의 일상생활에...  [쓰레기 매립장, 악취, 쾌쾌하게]\n",
       "1  쓰레기 매립장에서 악취가 쾌쾌하게 발생하고 있습니다. 이는 주변 환경을 심각하게 오...  [쓰레기 매립장, 악취, 쾌쾌하게]\n",
       "2  쓰레기 매립장에서 악취가 쾌쾌하게 발생하고 있습니다. 이로 인해 주민들이 극심한 불...  [쓰레기 매립장, 악취, 쾌쾌하게]\n",
       "3  쓰레기 매립장에서 악취가 쾌쾌하게 발생하고 있습니다. 이 문제로 인해 지역 주민들이...  [쓰레기 매립장, 악취, 쾌쾌하게]\n",
       "4  쓰레기 매립장에서 악취가 쾌쾌하게 발생하고 있습니다. 주변의 자연 생태계까지 악영향...  [쓰레기 매립장, 악취, 쾌쾌하게]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(df['keywords']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data:\n",
      "                                                      text  \\\n",
      "5918002  도심 개발 공사장 주변에서 불쾌한 냄새가 오랫동안 남아있는 수준으로 발생 중입니다....   \n",
      "5957914  최근 운동장 공사장에서 먼지가 오랫동안 남아있는 나기 시작했어요. 공사 현장에서 발...   \n",
      "2907278  안녕하세요. 사료 공장 근처에 말린 사료 냄새가 압박감 있게 퍼지고 있어요. 악취 ...   \n",
      "268308   저녁에 공원 주변 쓰레기장에서 침투성 냄새가 거슬리게 발생해서 너무 불편했습니다. ...   \n",
      "4675819  지난주부터 집 근처 쓰레기통에서 마른 흙 냄새가 혼합되게 발생하고 있습니다. 냄새로...   \n",
      "\n",
      "                               keywords  \n",
      "5918002  [도심 개발 공사장, 불쾌한 냄새, 오랫동안 남아있는]  \n",
      "5957914        [운동장 공사장, 먼지, 오랫동안 남아있는]  \n",
      "2907278       [사료 공장, 말린 사료 냄새, 압박감 있게]  \n",
      "268308       [공원 주변 쓰레기장, 침투성 냄새, 거슬리게]  \n",
      "4675819      [집 근처 쓰레기통, 마른 흙 냄새, 혼합되게]  \n",
      "\n",
      "Validation Data:\n",
      "                                                      text  \\\n",
      "5961388  오늘 운동장 공사장 주변을 걷다가 기름 냄새가 스산하게 퍼지는 걸 느꼈습니다. 공사...   \n",
      "5604857  오늘 공공시설 공사 현장 근처에서 고무 타는 냄새가 역하게 나더라고요. 환경 단체가...   \n",
      "5996629  철도 터널 공사장에서 고무 타는 냄새가 자극적으로 상태입니다. 먼지와 냄새가 바람을...   \n",
      "3496443  주민들이 지속적으로 소음을 호소하고 있습니다. 해가 뜨기 전에서 바람을 타고 퍼지는...   \n",
      "679929   악취 문제 해결이 지연될 경우 추가적인 환경 피해가 예상됩니다. 도로 공사 현장 쓰...   \n",
      "\n",
      "                               keywords  \n",
      "5961388          [운동장 공사장, 기름 냄새, 스산하게]  \n",
      "5604857     [공공시설 공사 현장, 고무 타는 냄새, 역하게]  \n",
      "5996629    [철도 터널 공사장, 고무 타는 냄새, 자극적으로]  \n",
      "3496443  [해가 뜨기 전, 바람을 타고 퍼지는 냄새, 날카롭게]  \n",
      "679929    [도로 공사 현장 쓰레기장, 더러운 냄새, 끈질기게]  \n",
      "Train size: 4324530, Validation size: 1853370\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터를 70:30 비율로 나누기\n",
    "def split_data(df, train_ratio = 0.7):\n",
    "    \"\"\"\n",
    "    DataFrame을 train과 val로 나눔\n",
    "    \"\"\"\n",
    "    train_df, val_df = train_test_split(df, train_size = train_ratio, random_state = 42, shuffle = True)\n",
    "    return train_df, val_df\n",
    "\n",
    "# train, val로 나누기\n",
    "train_df, val_df = split_data(df)\n",
    "\n",
    "train_df.to_csv('/home/yjtech2/Desktop/yurim/LLM/Data/smell_keyword/train_df.csv', index = False)\n",
    "val_df.to_csv('/home/yjtech2/Desktop/yurim/LLM/Data/smell_keyword/val_df.csv', index = False)\n",
    "\n",
    "# 나눈 데이터 확인\n",
    "print(\"Train Data:\")\n",
    "print(train_df.head())\n",
    "print(\"\\nValidation Data:\")\n",
    "print(val_df.head())\n",
    "\n",
    "# 데이터 크기 확인\n",
    "print(f\"Train size: {len(train_df)}, Validation size: {len(val_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4324530\n",
      "1853370\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "train_df = pd.read_csv('/home/yjtech2/Desktop/yurim/LLM/Data/smell_keyword/train_df.csv')\n",
    "val_df = pd.read_csv('/home/yjtech2/Desktop/yurim/LLM/Data/smell_keyword/val_df.csv')\n",
    "\n",
    "\n",
    "# 데이터셋 전체 변환\n",
    "if train_df['keywords'].dtype == 'object':  # keywords가 문자열인지 확인\n",
    "    train_df['keywords'] = train_df['keywords'].apply(eval)  # 또는 json.loads\n",
    "\n",
    "# val_df의 'keywords' 컬럼 문자열 -> 리스트 변환\n",
    "if val_df['keywords'].dtype == 'object':  # keywords가 문자열인지 확인\n",
    "    val_df['keywords'] = val_df['keywords'].apply(eval)  # 또는 json.loads\n",
    "\n",
    "train_data_dict = train_df.to_dict(orient='list')\n",
    "train_dataset = Dataset.from_dict(train_data_dict)\n",
    "train_dataset\n",
    "print(len(train_dataset))\n",
    "\n",
    "val_data_dict = val_df.to_dict(orient='list')\n",
    "val_dataset = Dataset.from_dict(val_data_dict)\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['안녕하세요. 오늘 건축 공사장에서 건축 폐자재 냄새가 찌르는 듯이 나더라고요. 냄새와 먼지로 인해 지역 이미지가 나빠지고 있습니다.',\n",
       " '이 문제로 인해 지역 주민들의 건강과 안전이 위협받고 있어 신속한 해결이 요구됩니다. 건축 공사장에서 건축 폐자재 냄새가 무겁고 답답하게 발생하고 있습니다.',\n",
       " '지난주부터 지하 상가 공사장에서 녹슨 금속 냄새가 날카롭게 발생하고 있습니다. 주민들이 집을 떠나 피난처를 찾고 있는 상황입니다.',\n",
       " '흙 냄새 때문에 안개가 자욱한 저수지 주변 근처를 다니기 어려운 수준입니다. 문제 해결이 지연될 경우 지역 이탈 인구가 증가할 수 있습니다.',\n",
       " '오늘 농촌 지역 축사 근처에서 발효된 냄새가 집요하게 나더라고요. 특히 여름철 냄새가 더욱 심각해지는 문제를 겪고 있습니다.',\n",
       " '지난주부터 초고층 건물 공사장에서 차가운 금속 냄새가 지독하게 발생하고 있습니다. 냄새와 함께 소음 문제도 지속적으로 발생하고 있습니다.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.iloc[324:330]['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['도심 개발 공사장', '불쾌한 냄새', '오랫동안 남아있는']\n",
      "도심 개발 공사장\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0]['keywords'])  \n",
    "print(train_dataset[0]['keywords'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '오늘 운동장 공사장 주변을 걷다가 기름 냄새가 스산하게 퍼지는 걸 느꼈습니다. 공사장 문제로 주민들이 민원을 계속 제기하고 있습니다.',\n",
       " 'keywords': ['운동장 공사장', '기름 냄새', '스산하게']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Train Dataset Size: 4324530\n",
      "Sampled Train Dataset Size: 4324\n",
      "Original Validation Dataset Size: 1853370\n",
      "Sampled Validation Dataset Size: 1853\n"
     ]
    }
   ],
   "source": [
    "# from datasets import Dataset\n",
    "# import random\n",
    "\n",
    "# def sample_dataset(dataset, fraction):\n",
    "#     \"\"\"\n",
    "#     데이터셋에서 지정된 비율만큼 샘플링\n",
    "#     \"\"\"\n",
    "#     sample_size = int(len(dataset) * fraction)\n",
    "#     sampled_indices = random.sample(range(len(dataset)), sample_size)  # 랜덤 인덱스 선택\n",
    "#     return dataset.select(sampled_indices)\n",
    "\n",
    "# # Train과 Val 데이터셋 샘플링\n",
    "# train_sampled_dataset = sample_dataset(train_dataset, 0.001)\n",
    "# val_sampled_dataset = sample_dataset(val_dataset, 0.001)\n",
    "\n",
    "# # 샘플링 후 데이터 크기 확인\n",
    "# print(\"Original Train Dataset Size:\", len(train_dataset))\n",
    "# print(\"Sampled Train Dataset Size:\", len(train_sampled_dataset))\n",
    "# print(\"Original Validation Dataset Size:\", len(val_dataset))\n",
    "# print(\"Sampled Validation Dataset Size:\", len(val_sampled_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['학교 신축 공사장', '먼지', '불쾌하게']\n"
     ]
    }
   ],
   "source": [
    "# # 데이터 타입 확인\n",
    "# print(type(val_sampled_dataset[0]['keywords']))  # <class 'str'>일 가능성이 큼\n",
    "\n",
    "# # keywords 내용 확인\n",
    "# print(val_sampled_dataset[0]['keywords'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 16:28:17.727865: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-27 16:28:17.750923: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-27 16:28:18.001700: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from typing import Dict\n",
    "import time\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AdamW,\n",
    "    DataCollatorForSeq2Seq,\n",
    ")\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from mecab import MeCab\n",
    "\n",
    "class CustomKeyBERTTrainer:\n",
    "    def __init__(self, model_name: str, **kwargs):\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        if self.device == \"cuda\":\n",
    "            print(f\"GPU Model: {torch.cuda.get_device_name(0)}\")\n",
    "            print(f\"Available GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(self.device)\n",
    "        self.optimizer = AdamW(self.model.parameters(), lr=kwargs.get(\"learning_rate\", 2e-5))\n",
    "        self.max_length = kwargs.get(\"max_length\", 128)\n",
    "        self.training_args = kwargs\n",
    "        self.save_dir = kwargs.get(\"save_dir\", \"./best_model\")\n",
    "        self.mecab = MeCab()  # MeCab 초기화\n",
    "        self.best_model_path = os.path.join(self.save_dir, \"pytorch_model.bin\")\n",
    "        self.tokenizer_path = self.save_dir\n",
    "        \n",
    "        self.history = {\n",
    "            'train_loss': [],\n",
    "            'val_loss': [],\n",
    "            'epoch_times': [],\n",
    "            'best_epoch': 0\n",
    "        }\n",
    "\n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "        \n",
    "    def _mecab_tokenize(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        MeCab을 사용하여 입력 텍스트에서 명사, 형용사, 부사를 추출\n",
    "        \"\"\"\n",
    "        pos_tags = self.mecab.pos(text)  # 품사 태그 추출\n",
    "        # 원하는 품사 필터링: 명사(NNG, NNP), 형용사(VA), 부사(MAG, MAJ)\n",
    "        keywords = [\n",
    "            word for word, pos in pos_tags if pos in (\"NNG\", \"NNP\", \"VA\", \"MAG\", \"MAJ\")\n",
    "        ]\n",
    "        return \" \".join(keywords)  # 추출한 단어를 공백으로 연결하여 반환\n",
    "    \n",
    "    def preprocess_data(self, examples: Dict) -> Dict:\n",
    "        # MeCab 형태소 분석과 품사 필터링 적용\n",
    "        examples[\"text\"] = [self._mecab_tokenize(text) for text in examples[\"text\"]]\n",
    "        \n",
    "        # 기존 코드 유지\n",
    "        inputs = [f\"키워드 추출: {text}\" for text in examples[\"text\"]]\n",
    "        model_inputs = self.tokenizer(\n",
    "            inputs,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=None  # 텐서 변환을 DataCollator에 맡김\n",
    "        )\n",
    "\n",
    "        # 레이블(키워드) 처리\n",
    "        labels = [\", \".join(keywords) if keywords else \"\" for keywords in examples[\"keywords\"]]\n",
    "        \n",
    "        with self.tokenizer.as_target_tokenizer():\n",
    "            tokenized_labels = self.tokenizer(\n",
    "                labels,\n",
    "                max_length=self.max_length,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_tensors=None  # 텐서 변환을 DataCollator에 맡김\n",
    "            )\n",
    "\n",
    "        # -100으로 패딩 토큰을 마스킹\n",
    "        labels = tokenized_labels[\"input_ids\"]\n",
    "        for i in range(len(labels)):\n",
    "            for j in range(len(labels[i])):\n",
    "                if labels[i][j] == self.tokenizer.pad_token_id:\n",
    "                    labels[i][j] = -100\n",
    "\n",
    "        model_inputs[\"labels\"] = labels\n",
    "        return model_inputs\n",
    "        \n",
    "    def save_model_and_tokenizer(self, epoch=None, is_best=False):\n",
    "        \"\"\"\n",
    "        최고 성능 모델만 저장하고 이전 모델을 삭제\n",
    "        \"\"\"\n",
    "        if is_best:\n",
    "            # 이전 최고 모델 디렉토리 삭제\n",
    "            if os.path.exists(self.best_model_path):\n",
    "                print(f\"Deleting previous best model at {self.best_model_path}\")\n",
    "                os.system(f\"rm -rf {self.best_model_path}\")\n",
    "            \n",
    "            # 새로운 최고 모델 저장\n",
    "            save_path = os.path.join(self.save_dir, f\"best_model_epoch_{epoch}\")\n",
    "            os.makedirs(save_path, exist_ok=True)\n",
    "            self.model.save_pretrained(save_path)\n",
    "            self.tokenizer.save_pretrained(save_path)\n",
    "            torch.save(self.history, os.path.join(save_path, 'training_history.pt'))\n",
    "            print(f\"New best model saved at {save_path}\")\n",
    "\n",
    "            # 최고 모델 경로 업데이트\n",
    "            self.best_model_path = save_path\n",
    "\n",
    "    def calculate_metrics(self, predictions, labels):\n",
    "        predictions = torch.argmax(predictions, dim=-1)\n",
    "        correct = (predictions == labels).masked_fill(labels == -100, 0)\n",
    "        accuracy = correct.sum().item() / (labels != -100).sum().item()\n",
    "        return accuracy\n",
    "\n",
    "    def train(self, train_dataset, valid_dataset=None):\n",
    "        start_time = time.time()\n",
    "        print(f\"\\nStarting training at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(f\"Training parameters:\")\n",
    "        print(f\"- Batch size: {self.training_args['batch_size']}\")\n",
    "        print(f\"- Learning rate: {self.training_args.get('learning_rate', '2e-5')}\")\n",
    "        print(f\"- Max length: {self.max_length}\")\n",
    "        print(f\"- Number of epochs: {self.training_args['num_epochs']}\")\n",
    "        print(f\"- Training samples: {len(train_dataset)}\")\n",
    "        if valid_dataset:\n",
    "            print(f\"- Validation samples: {len(valid_dataset)}\")\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "        # 데이터셋 전처리\n",
    "        print(\"Preprocessing training data...\")\n",
    "        train_dataset = train_dataset.map(\n",
    "            self.preprocess_data,\n",
    "            batched=True,\n",
    "            remove_columns=train_dataset.column_names,\n",
    "            desc=\"Processing training data\"\n",
    "        )\n",
    "\n",
    "        if valid_dataset is not None:\n",
    "            print(\"Preprocessing validation data...\")\n",
    "            valid_dataset = valid_dataset.map(\n",
    "                self.preprocess_data,\n",
    "                batched=True,\n",
    "                remove_columns=valid_dataset.column_names,\n",
    "                desc=\"Processing validation data\"\n",
    "            )\n",
    "\n",
    "        # DataCollator 설정\n",
    "        data_collator = DataCollatorForSeq2Seq(\n",
    "            tokenizer=self.tokenizer,\n",
    "            model=self.model,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # DataLoader 설정 (num_workers=0으로 변경하여 멀티프로세싱 관련 오류 방지)\n",
    "        train_dataloader = torch.utils.data.DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=self.training_args[\"batch_size\"],\n",
    "            shuffle=True,\n",
    "            collate_fn=data_collator,\n",
    "            num_workers=0,\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "        if valid_dataset is not None:\n",
    "            valid_dataloader = torch.utils.data.DataLoader(\n",
    "                valid_dataset,\n",
    "                batch_size=self.training_args[\"batch_size\"],\n",
    "                shuffle=False,\n",
    "                collate_fn=data_collator,\n",
    "                num_workers=0,\n",
    "                pin_memory=True\n",
    "            )\n",
    "        best_val_loss = float('inf')\n",
    "        early_stopping_counter = 0\n",
    "        early_stopping_patience = self.training_args.get('patience', 3)\n",
    "\n",
    "        for epoch in range(self.training_args[\"num_epochs\"]):\n",
    "            epoch_start_time = time.time()\n",
    "            \n",
    "            self.model.train()\n",
    "            epoch_loss = 0\n",
    "            epoch_accuracy = 0\n",
    "            train_steps = 0\n",
    "            \n",
    "            progress_bar = tqdm(train_dataloader, desc=f\"Training Epoch {epoch + 1}\")\n",
    "            batch_losses = []\n",
    "            batch_accuracies = []\n",
    "            \n",
    "            for batch_idx, batch in enumerate(progress_bar):\n",
    "                input_ids = batch[\"input_ids\"].to(self.device)\n",
    "                attention_mask = batch[\"attention_mask\"].to(self.device)\n",
    "                labels = batch[\"labels\"].to(self.device)\n",
    "\n",
    "                outputs = self.model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels,\n",
    "                )\n",
    "                \n",
    "                loss = outputs.loss # 손실 계산\n",
    "                accuracy = self.calculate_metrics(outputs.logits, labels)\n",
    "                \n",
    "                loss.backward()# 손실 역전파 \n",
    "                self.optimizer.step() # 가중치 업데이트\n",
    "                self.optimizer.zero_grad() # 그래디언트 초기화\n",
    "\n",
    "                batch_losses.append(loss.item())\n",
    "                batch_accuracies.append(accuracy)\n",
    "                \n",
    "                current_loss = np.mean(batch_losses[-100:])\n",
    "                current_accuracy = np.mean(batch_accuracies[-100:])\n",
    "                progress_bar.set_postfix({\n",
    "                    'loss': f'{current_loss:.4f}',\n",
    "                    'accuracy': f'{current_accuracy:.4f}',\n",
    "                    'batch': f'{batch_idx + 1}/{len(train_dataloader)}'\n",
    "                })\n",
    "\n",
    "            avg_train_loss = np.mean(batch_losses)\n",
    "            avg_train_accuracy = np.mean(batch_accuracies)\n",
    "\n",
    "            if valid_dataset is not None:\n",
    "                self.model.eval()\n",
    "                val_losses = []\n",
    "                val_accuracies = []\n",
    "\n",
    "                print(\"\\nRunning validation...\")\n",
    "                with torch.no_grad():\n",
    "                    for batch in tqdm(valid_dataloader, desc=\"Validating\"):\n",
    "                        input_ids = batch[\"input_ids\"].to(self.device)\n",
    "                        attention_mask = batch[\"attention_mask\"].to(self.device)\n",
    "                        labels = batch[\"labels\"].to(self.device)\n",
    "\n",
    "                        outputs = self.model(\n",
    "                            input_ids=input_ids,\n",
    "                            attention_mask=attention_mask,\n",
    "                            labels=labels,\n",
    "                        )\n",
    "                        \n",
    "                        loss = outputs.loss\n",
    "                        accuracy = self.calculate_metrics(outputs.logits, labels)\n",
    "                        \n",
    "                        val_losses.append(loss.item())\n",
    "                        val_accuracies.append(accuracy)\n",
    "\n",
    "                avg_val_loss = np.mean(val_losses)\n",
    "                avg_val_accuracy = np.mean(val_accuracies)\n",
    "\n",
    "                if avg_val_loss < best_val_loss:\n",
    "                    best_val_loss = avg_val_loss\n",
    "                    early_stopping_counter = 0\n",
    "                    self.history['best_epoch'] = epoch + 1\n",
    "                    print(f\"\\nNew best validation loss: {best_val_loss:.4f}\")\n",
    "                    self.save_model_and_tokenizer(epoch + 1, is_best=True)  # 최고 모델만 저장\n",
    "                else:\n",
    "                    early_stopping_counter += 1\n",
    "\n",
    "\n",
    "            epoch_time = time.time() - epoch_start_time\n",
    "            self.history['epoch_times'].append(epoch_time)\n",
    "            self.history['train_loss'].append(avg_train_loss)\n",
    "            if valid_dataset is not None:\n",
    "                self.history['val_loss'].append(avg_val_loss)\n",
    "\n",
    "            # Print epoch summary\n",
    "            print(f\"\\nEpoch {epoch + 1} Summary:\")\n",
    "            print(f\"Time taken: {epoch_time:.2f} seconds\")\n",
    "            print(f\"Average training loss: {avg_train_loss:.4f}\")\n",
    "            print(f\"Training accuracy: {avg_train_accuracy:.4f}\")\n",
    "            if valid_dataset is not None:\n",
    "                print(f\"Validation loss: {avg_val_loss:.4f}\")\n",
    "                print(f\"Validation accuracy: {avg_val_accuracy:.4f}\")\n",
    "                print(f\"Best validation loss so far: {best_val_loss:.4f}\")\n",
    "                print(f\"Early stopping counter: {early_stopping_counter}/{early_stopping_patience}\")\n",
    "\n",
    "            if early_stopping_counter >= early_stopping_patience:\n",
    "                print(\"\\nEarly stopping triggered.\")\n",
    "                break\n",
    "    def predict(self, text: str) -> str:\n",
    "        \"\"\"모델 추론\"\"\"\n",
    "        inputs = self.tokenizer(\n",
    "            f\"키워드 추출: {self._normalize_text(text)}\",\n",
    "            return_tensors=\"pt\",\n",
    "            max_length=self.max_length,\n",
    "            truncation=True,\n",
    "        ).to(self.device)\n",
    "\n",
    "        outputs = self.model.generate(\n",
    "            inputs[\"input_ids\"], max_length=self.max_length, num_beams=5\n",
    "        )\n",
    "        return self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    def _normalize_text(self, text: str) -> str:\n",
    "        return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU Model: NVIDIA GeForce RTX 4080\n",
      "Available GPU memory: 15.59 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yjtech2/Desktop/yurim/anaconda3/envs/venv-llm/lib/python3.8/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Parameter 'function'=<bound method CustomKeyBERTTrainer.preprocess_data of <__main__.CustomKeyBERTTrainer object at 0x7f989f0f1550>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training at: 2024-11-27 16:28:54\n",
      "Training parameters:\n",
      "- Batch size: 8\n",
      "- Learning rate: 0.0001\n",
      "- Max length: 128\n",
      "- Number of epochs: 15\n",
      "- Training samples: 4324530\n",
      "- Validation samples: 1853370\n",
      "\n",
      "==================================================\n",
      "\n",
      "Preprocessing training data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "452dd3a4129947acacb9682bc042c12e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing training data:   0%|          | 0/4324530 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yjtech2/Desktop/yurim/anaconda3/envs/venv-llm/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:4114: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing validation data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed941bdb8094fa29a6a242f89462137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing validation data:   0%|          | 0/1853370 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"  # 멀티프로세싱 경고 방지\n",
    "\n",
    "trainer = CustomKeyBERTTrainer(\n",
    "    model_name=\"facebook/bart-base\", # t5-base     skt/kobart-base-v2\n",
    "    max_length=128,\n",
    "    learning_rate=1e-4,\n",
    "    batch_size=8,\n",
    "    num_epochs=15,\n",
    "    gradient_accumulation_steps=8,\n",
    "    patience=3 # 몇 에폭마다 체크포인트 저장할지\n",
    ")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    torch.cuda.empty_cache()  # GPU 메모리 초기화\n",
    "    trainer.train(train_dataset, val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('/home/yjtech2/Desktop/yurim/LLM/Pre_processing/smell_keyword/best_model/best_model_epoch_4')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/yjtech2/Desktop/yurim/LLM/Pre_processing/smell_keyword/best_model/best_model_epoch_4\")\n",
    "print(\"Model and tokenizer loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원래 문장:  여보세요? 네, 여보세요? 포항시청 맞죠? 네, 맞습니다. 아니 여기 지금 아침부터 쓰레기 냄새가 너무 많이 납니다. 아 쓰레기 냄새요? 혹시 어디서 나는지 정확하게 말씀해 주실 수 있을까요? 아침에 버스정류장 가는 다리에서 썩은 음식물 냄새가 납니다.        아 버스정류장 가는 다리요?? 네, 빨리 조치해 주세요. 네 알겠습니다. 감사합니다..\n",
      "키워드 추출:  늤이 맞습니다, 아침부터, 쓰레기게\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# 저장된 모델 경로\n",
    "saved_model_path = \"/home/yjtech2/Desktop/yurim/LLM/Pre_processing/smell_keyword/best_model/best_model_epoch_10\"\n",
    "\n",
    "# 모델과 토크나이저 불러오기\n",
    "tokenizer = AutoTokenizer.from_pretrained(saved_model_path, local_files_only=True)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(saved_model_path, local_files_only=True).to('cpu')\n",
    "\n",
    "# 예측 테스트\n",
    "text = '여보세요? 네, 여보세요? 포항시청 맞죠? 네, 맞습니다. 아니 여기 지금 아침부터 쓰레기 냄새가 너무 많이 납니다. 아 쓰레기 냄새요? 혹시 어디서 나는지 정확하게 말씀해 주실 수 있을까요? 아침에 버스정류장 가는 다리에서 썩은 음식물 냄새가 납니다.\\\n",
    "        아 버스정류장 가는 다리요?? 네, 빨리 조치해 주세요. 네 알겠습니다. 감사합니다..'\n",
    "inputs = tokenizer(\n",
    "    f\"키워드 추출: {text}\",\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=128,\n",
    "    truncation=True\n",
    ").to(\"cpu\")\n",
    "\n",
    "outputs = model.generate(\n",
    "    inputs[\"input_ids\"],\n",
    "    max_length=128,\n",
    "    num_beams=5,\n",
    "    length_penalty=0.7,\n",
    "    repetition_penalty=1.2,\n",
    "    early_stopping=True\n",
    ")\n",
    "\n",
    "result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(\"원래 문장: \", text)\n",
    "print(\"키워드 추출: \", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
