{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "import datasets\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_datasets_from_csv(test_file):\n",
    "    # Load CSV file into a DataFrame\n",
    "    df = pd.read_csv(test_file)\n",
    "    \n",
    "    # Ensure the DataFrame has the necessary columns\n",
    "    if 'id' not in df.columns or 'err_sentence' not in df.columns:\n",
    "        raise ValueError(\"CSV file must contain 'id' and 'err_sentence' columns.\")\n",
    "    \n",
    "    # Convert DataFrame to Dataset\n",
    "    dataset = datasets.Dataset.from_pandas(df)\n",
    "    \n",
    "    # Wrap it in a DatasetDict\n",
    "    dataset_dict = {\n",
    "        'test': dataset\n",
    "    }\n",
    "    return datasets.DatasetDict(dataset_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngram(text, n_gram):\n",
    "    ngram_list = []\n",
    "    text_length = len(text)\n",
    "    for i in range(text_length - n_gram + 1):\n",
    "        ngram_list.append(text[i:i+n_gram])\n",
    "    return ngram_list\n",
    "\n",
    "def calc_f_05(cor_sentence, prd_sentence, n_gram):\n",
    "    prd_word_list = get_ngram(prd_sentence, n_gram)\n",
    "    cor_word_list = get_ngram(cor_sentence, n_gram)\n",
    "    \n",
    "    cnt = 0\n",
    "    for idx in range(len(prd_word_list)):\n",
    "        start_idx = 0\n",
    "        end_idx = idx + 2\n",
    "        if idx > 2:\n",
    "            start_idx = idx - 2\n",
    "        if prd_word_list[idx] in cor_word_list[start_idx:end_idx]:\n",
    "            cnt += 1\n",
    "    \n",
    "    if not prd_word_list:\n",
    "        return 0, 0, 0\n",
    "    \n",
    "    precision = cnt / len(prd_word_list)\n",
    "    recall = cnt / len(cor_word_list)\n",
    "    \n",
    "    if not (0.25 * precision + recall):\n",
    "        return 0, 0, 0\n",
    "    \n",
    "    f_05 = 1.25 * (precision * recall) / (0.25 * precision + recall)\n",
    "    \n",
    "    return precision, recall, f_05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_test(gpus='cpu', model_path=None, test_file=None, eval_length=None, save_path=None, pb=False):\n",
    "    # Set the device to CPU or CUDA based on the input\n",
    "    device = torch.device(gpus)\n",
    "\n",
    "    # Load model and tokenizer\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "    # Move model to the specified device\n",
    "    model.to(device)\n",
    "    \n",
    "    # Load dataset\n",
    "    dataset = load_test_datasets_from_csv(test_file)\n",
    "    \n",
    "    # inference data\n",
    "    id_list = []\n",
    "    err_sentence_list = []\n",
    "    prd_sentence_list = []\n",
    "    \n",
    "    data_len = len(dataset['test'])\n",
    "    if eval_length:\n",
    "        data_len = min(eval_length, len(dataset['test']))\n",
    "    \n",
    "    for n in tqdm(range(data_len), disable=pb):\n",
    "        data_id = dataset['test'][n]['id']\n",
    "        id_list.append(data_id)\n",
    "        err_sentence = dataset['test'][n]['err_sentence']\n",
    "        err_sentence_list.append(err_sentence)\n",
    "        tokenized = tokenizer(err_sentence, return_tensors='pt')\n",
    "        input_ids = tokenized['input_ids']\n",
    "        input_ids = input_ids.to(device)\n",
    "        res = model.generate(\n",
    "            inputs=input_ids,\n",
    "            num_beams=5,  # Adjust beam size as needed\n",
    "            max_length=128,  # Maximum length of the output\n",
    "            no_repeat_ngram_size=2\n",
    "        ).cpu().tolist()[0]\n",
    "        prd_sentence = tokenizer.decode(res, skip_special_tokens=True).strip()\n",
    "        prd_sentence_list.append(prd_sentence)\n",
    "        \n",
    "        # Print prediction results for each sentence\n",
    "        print(f'Input Sentence: {err_sentence}')\n",
    "        print(f'Predicted Sentence: {prd_sentence}')\n",
    "        print('=' * 50)\n",
    "    \n",
    "    # Save predictions\n",
    "    save_file_name = os.path.split(test_file)[-1].replace('.json', '') + '_predictions.csv'\n",
    "    save_file_path = os.path.join(save_path, save_file_name)\n",
    "    _df = pd.DataFrame({\n",
    "        'id': id_list,\n",
    "        'err_sentence': err_sentence_list,\n",
    "        'prd_sentence': prd_sentence_list\n",
    "    })\n",
    "    _df.to_csv(save_file_path, index=False)\n",
    "    print(f'Saved predictions to {save_file_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설정값 정의\n",
    "gpus = 'cpu'  # 'cuda:0'로 설정 가능\n",
    "model_path = '/home/yjtech2/Desktop/yurim/LLM/Pre_processing/spelling/grm_model_checkpoint'\n",
    "test_file = \"./path/to/test.csv\"  # CSV 파일 경로\n",
    "eval_length = 10  # None으로 설정하면 전체 데이터 사용\n",
    "save_path = \"./results\"\n",
    "pb = True  # 프로그래스바 표시 여부\n",
    "\n",
    "# 저장 경로 생성\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# 실행\n",
    "dataset = load_test_datasets_from_csv(test_file)  # CSV 파일에서 데이터셋 로드\n",
    "my_test(gpus=gpus, model_path=model_path, test_file=test_file, eval_length=eval_length, save_path=save_path, pb=pb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
