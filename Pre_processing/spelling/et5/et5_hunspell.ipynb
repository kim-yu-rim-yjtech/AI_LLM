{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yjtech2/Desktop/yurim/anaconda3/envs/venv-llm/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-11-19 15:47:36.546879: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-19 15:47:36.571783: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-19 15:47:36.943899: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로드\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    10 non-null     object\n",
      "dtypes: object(1)\n",
      "memory usage: 208.0+ bytes\n",
      "None\n",
      "Applying spacing correction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing corrections: 100%|██████████| 10/10 [00:00<00:00, 120.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying spelling correction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing corrections: 100%|██████████| 10/10 [00:01<00:00,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Results ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import (\n",
    "    T5ForConditionalGeneration, \n",
    "    T5Tokenizer, \n",
    "    AutoModelForTokenClassification, \n",
    "    AutoTokenizer\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class TextCorrector:\n",
    "    def __init__(self):\n",
    "        # 띄어쓰기 모델 초기화\n",
    "        self.spacing_tokenizer = AutoTokenizer.from_pretrained(\"fiveflow/roberta-base-spacing\")\n",
    "        self.spacing_model = AutoModelForTokenClassification.from_pretrained(\"fiveflow/roberta-base-spacing\")\n",
    "        \n",
    "        # 맞춤법 모델 초기화\n",
    "        self.spelling_tokenizer = T5Tokenizer.from_pretrained('j5ng/et5-typos-corrector')\n",
    "        self.spelling_model = T5ForConditionalGeneration.from_pretrained('j5ng/et5-typos-corrector')\n",
    "        \n",
    "        # GPU 설정\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.spacing_model = self.spacing_model.to(self.device)\n",
    "        self.spelling_model = self.spelling_model.to(self.device)\n",
    "        \n",
    "        # 띄어쓰기 레이블\n",
    "        self.spacing_labels = [\"UNK\", \"PAD\", \"O\", \"B\", \"I\", \"E\", \"S\"]\n",
    "\n",
    "    # 띄어쓰기 교정\n",
    "    def correct_spacing(self, text):\n",
    "        if not isinstance(text, str) or not text.strip():\n",
    "            return \"\"\n",
    "            \n",
    "        try:\n",
    "            max_length = 512 - 2\n",
    "            org_text = text.replace(\" \", \"\")\n",
    "            results = []\n",
    "            \n",
    "            for start_idx in range(0, len(org_text), max_length):\n",
    "                chunk = org_text[start_idx:start_idx + max_length]\n",
    "                \n",
    "                # 토큰화\n",
    "                tokens = [self.spacing_tokenizer.cls_token_id]\n",
    "                tokens.extend(sum([self.spacing_tokenizer.encode(char)[1:-1] for char in chunk], []))\n",
    "                tokens.append(self.spacing_tokenizer.sep_token_id)\n",
    "                \n",
    "                # 예측\n",
    "                with torch.no_grad():\n",
    "                    inputs = torch.tensor([tokens]).to(self.device)\n",
    "                    outputs = self.spacing_model(inputs)\n",
    "                    predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "                \n",
    "                # 결과 생성\n",
    "                result = \"\"\n",
    "                for idx, pred in enumerate(predictions.squeeze()[1:-1]):\n",
    "                    if idx >= len(chunk):\n",
    "                        break\n",
    "                    result += chunk[idx]\n",
    "                    if self.spacing_labels[pred] in [\"E\", \"S\"]:\n",
    "                        result += \" \"\n",
    "                        \n",
    "                results.append(result.strip())\n",
    "            \n",
    "            return \" \".join(results).strip()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Spacing error: {str(e)}\")\n",
    "            return text\n",
    "\n",
    "    # 맞춤법 교정\n",
    "    def correct_spelling(self, text):\n",
    "        if not isinstance(text, str) or not text.strip():\n",
    "            return \"\"\n",
    "            \n",
    "        try:\n",
    "            max_length = 128 - 2\n",
    "            chunks = [text[i:i + max_length] for i in range(0, len(text), max_length)]\n",
    "            results = []\n",
    "            \n",
    "            for chunk in chunks:\n",
    "                inputs = self.spelling_tokenizer(\n",
    "                    \"맞춤법을 고쳐주세요: \" + chunk,\n",
    "                    return_tensors=\"pt\",\n",
    "                    truncation=True,\n",
    "                    max_length=max_length\n",
    "                ).to(self.device)\n",
    "                \n",
    "                outputs = self.spelling_model.generate(\n",
    "                    **inputs,\n",
    "                    max_length=max_length,\n",
    "                    num_beams=5,\n",
    "                    early_stopping=True\n",
    "                )\n",
    "                \n",
    "                result = self.spelling_tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "                if result:\n",
    "                    results.append(result)\n",
    "            \n",
    "            return \" \".join(results).strip() or \"\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Spelling error: {str(e)}\")\n",
    "            return \"\"\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "        return re.sub('[^\\w\\s]', '', text)\n",
    "\n",
    "def load_data(file_path):\n",
    "\n",
    "    \n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    print(df.info())\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_dataset(file_path):\n",
    "    # 데이터 로드 및 전처리기 초기화\n",
    "    print('데이터 로드')\n",
    "    df = load_data(file_path)\n",
    "    \n",
    "    corrector = TextCorrector()\n",
    "    \n",
    "    # 진행바 설정\n",
    "    tqdm.pandas(desc=\"Processing corrections\")\n",
    "    \n",
    "    # 띄어쓰기 교정\n",
    "    print(\"Applying spacing correction...\")\n",
    "    df['spacing_res_sentence'] = df['text'].progress_apply(corrector.correct_spacing)\n",
    "    \n",
    "    # 맞춤법 교정\n",
    "    print(\"Applying spelling correction...\")\n",
    "    df['spelling_res_sentence'] = df['spacing_res_sentence'].progress_apply(corrector.correct_spelling)\n",
    "    \n",
    "    # 텍스트 클리닝\n",
    "    df['spelling_res_sentence'] = df['spelling_res_sentence'].apply(corrector.clean_text)\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = '/home/yjtech2/Desktop/yurim/LLM/Data/text_test_data.xlsx'\n",
    "    result_df = process_dataset(file_path)\n",
    "    \n",
    "    print(\"\\n=== Results ===\")\n",
    "    result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing spacing correction: 100%|██████████| 10/10 [00:02<00:00,  4.09it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from hunspell import HunSpell\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def hunspell_basic(text):\n",
    "    try:\n",
    "        # Hunspell 객체 생성\n",
    "        hunspell = HunSpell(\n",
    "            '/home/yjtech2/Desktop/yurim/LLM/Pre_processing/spelling/hunspell/ko_KR.dic',\n",
    "            '/home/yjtech2/Desktop/yurim/LLM/Pre_processing/spelling/hunspell/ko_KR.aff'\n",
    "        )\n",
    "\n",
    "        # 결과 저장용 리스트\n",
    "        corrected_texts = []\n",
    "\n",
    "        # 문장에서 단어 추출\n",
    "        words = re.findall(r'\\b\\w+\\b', text)\n",
    "        \n",
    "        # 수정된 문장을 저장할 변수\n",
    "        corrected_sentence = text\n",
    "        \n",
    "        for word in words:\n",
    "            if not hunspell.spell(word):\n",
    "                suggestions = hunspell.suggest(word)\n",
    "                \n",
    "                if suggestions:\n",
    "                    corrected_word = suggestions[0]\n",
    "                    corrected_sentence = re.sub(r'\\b' + re.escape(word) + r'\\b', corrected_word, corrected_sentence, count=1)\n",
    "                    # print(f\"'{word}'를 '{corrected_word}'로 수정했습니다.\")\n",
    "                else:\n",
    "                    print(f\"'{word}'에 대한 제안이 없습니다.\")\n",
    "        \n",
    "        corrected_texts.append(corrected_sentence)\n",
    "        # print(f'\\n수정 전 문장: {text}')\n",
    "        # print(f'\\n수정 후 문장: {corrected_sentence}')\n",
    "        \n",
    "        return corrected_texts\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Hunspell 초기화 중 오류 발생: {e}\")\n",
    "        return []\n",
    "\n",
    "def process_dataframe(df, text_column):\n",
    "    # 진행바 표시\n",
    "    tqdm.pandas(desc=\"Processing spacing correction\")\n",
    "    \n",
    "    # 맞춤법 교정 적용\n",
    "    df[\"res_sentence\"] = df[text_column].progress_apply(hunspell_basic)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# 수행\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    processed_df = process_dataframe(result_df, \"spelling_res_sentence\")\n",
    "    \n",
    "    def text_clean(text):\n",
    "        pattern = '([ㄱ-ㅎㅏ-ㅣ]+)'  # 한글 자음, 모음 제거\n",
    "        text = re.sub(pattern, '', text)\n",
    "        \n",
    "        pattern = '[^\\w\\s]'         # 특수기호제거\n",
    "        text = re.sub(pattern, '', text)\n",
    "\n",
    "        return text \n",
    "    \n",
    "    processed_df['res_sentence'] = processed_df['res_sentence'].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spacing_res_sentence</th>\n",
       "      <th>spelling_res_sentence</th>\n",
       "      <th>res_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>음식물 쓰레기 냄세가 나요</td>\n",
       "      <td>음식물 쓰레기 냄세가 나요</td>\n",
       "      <td>음식물 쓰레기 냄새가 나요</td>\n",
       "      <td>음식물 쓰레기 냄새가 나요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>전라북도 순창군 ㅇㅇ면 마을 꼴목길에  퇴비를 가져다 놓음\\n바람이불면 골목안쪽으로...</td>\n",
       "      <td>전라북도 순창군 ㅇㅇ면 마을 꼴목길에 퇴비를 가져다 놓음 \\n바람 이불 면골 목안쪽...</td>\n",
       "      <td>전라북도 순창군 ᄋᄋ 면 마을 꼴 목길에 퇴비를 가져다 놓음 바람 이불 면골 목 안...</td>\n",
       "      <td>전라북도 순차군 아 면 마을 꼴 목기에 퇴비를 가져다 놓음 바람 이불 만골 목 안쪽...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>인도에 폐기물 컨테이너가 있어 통행 불편 및 악취로 불편합니다.\\n발리조치해 주시기...</td>\n",
       "      <td>인도에 폐기물 컨테이너가 있어 통행 불편 및 악취로 불편합니다. \\n발 리조치 해주...</td>\n",
       "      <td>인도에 폐기물 컨테이너가 있어 통행 불편 및 냄새로 불편합니다</td>\n",
       "      <td>인도에 폐기물 컨테이너가 있어 통행 불편 및 냄새로 불편합니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이웃집 에서 보일러 기름으로 추정되는 물질이 다량으로 유출되어 주변에 피해를 쥽니다</td>\n",
       "      <td>이웃집에서 보일러 기름으로 추정되는 물질이 다량으로 유출되어 주변에 피해를 쥽니다</td>\n",
       "      <td>이웃집에서 보일러 기름으로 추정되는 물질이 다량으로 유출되어 주변에 피해를 쥽니다</td>\n",
       "      <td>이웃집에서 보일러 기름으로 추정되는 물질이 다량으로 유출되어 주변에 피해를 잡니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>동국대 신공학관 근처 하수 처리 냄세 신고</td>\n",
       "      <td>동국대 신공학관 근처 하수 처리 냄세 신고</td>\n",
       "      <td>동국대 신공학관 근처 하수 처리 냄새 신고</td>\n",
       "      <td>동국도 신 공학관 근처 하수 처리 냄새 신고</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>층간소음 문제로 12년된 아파트 하자 점검 서비스가 있나요?\\n원룸형 아파트 인데요...</td>\n",
       "      <td>층간 소음 문제로 12년 된 아파트 하자 점검 서비스가 있나요? \\n원룸 형아파트인...</td>\n",
       "      <td>층간 소음 문제로 12년 된 아파트 하자 점검 서비스가 있나요 원룸 형 아파트인데요...</td>\n",
       "      <td>증간 소음 문제로 12년 된 아파트 하자 점검 서비스가 있나요 원룸 형 아파트인데요...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>건물 옆 주차장에 길고양들이 배설물을 싸고 있습니다</td>\n",
       "      <td>건물 옆 주차장에 길 고양들이 배설물을 싸고 있습니다</td>\n",
       "      <td>건물 옆 주차장에 길 고양들이 배설물을 싸고 있습니다</td>\n",
       "      <td>건물 옆 주차장에 길 고양들이 배설물을 싸고 있습니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>공공시설/ 길거리 흡연자가 녀무 많습니다</td>\n",
       "      <td>공공시설 / 길거리 흡연자가 녀무 많습니다</td>\n",
       "      <td>공공시설  길거리 흡연자가 너무 많습니다</td>\n",
       "      <td>공공시설  길거리 흡연자가 너무 많습니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>벌래와 모기 하수구냄새가 납니다</td>\n",
       "      <td>벌래와 모기 하수구 냄새가 납니다</td>\n",
       "      <td>벌래와 모기 하수구 냄새가 납니다</td>\n",
       "      <td>벌레와 모기 하수구 냄새가 납니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>바람이 동서족에서 불고 불쾌한 냄새가 납니다</td>\n",
       "      <td>바람이 동서족에서 불고 불쾌한 냄새가 납니다</td>\n",
       "      <td>바람이 동서족에서 불고 불쾌한 냄새가 납니다</td>\n",
       "      <td>바람이 동서 족에서 불고 불쾌한 냄새가 납니다</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                                     음식물 쓰레기 냄세가 나요   \n",
       "1  전라북도 순창군 ㅇㅇ면 마을 꼴목길에  퇴비를 가져다 놓음\\n바람이불면 골목안쪽으로...   \n",
       "2  인도에 폐기물 컨테이너가 있어 통행 불편 및 악취로 불편합니다.\\n발리조치해 주시기...   \n",
       "3     이웃집 에서 보일러 기름으로 추정되는 물질이 다량으로 유출되어 주변에 피해를 쥽니다   \n",
       "4                            동국대 신공학관 근처 하수 처리 냄세 신고   \n",
       "5  층간소음 문제로 12년된 아파트 하자 점검 서비스가 있나요?\\n원룸형 아파트 인데요...   \n",
       "6                       건물 옆 주차장에 길고양들이 배설물을 싸고 있습니다   \n",
       "7                             공공시설/ 길거리 흡연자가 녀무 많습니다   \n",
       "8                                  벌래와 모기 하수구냄새가 납니다   \n",
       "9                           바람이 동서족에서 불고 불쾌한 냄새가 납니다   \n",
       "\n",
       "                                spacing_res_sentence  \\\n",
       "0                                     음식물 쓰레기 냄세가 나요   \n",
       "1  전라북도 순창군 ㅇㅇ면 마을 꼴목길에 퇴비를 가져다 놓음 \\n바람 이불 면골 목안쪽...   \n",
       "2  인도에 폐기물 컨테이너가 있어 통행 불편 및 악취로 불편합니다. \\n발 리조치 해주...   \n",
       "3      이웃집에서 보일러 기름으로 추정되는 물질이 다량으로 유출되어 주변에 피해를 쥽니다   \n",
       "4                            동국대 신공학관 근처 하수 처리 냄세 신고   \n",
       "5  층간 소음 문제로 12년 된 아파트 하자 점검 서비스가 있나요? \\n원룸 형아파트인...   \n",
       "6                      건물 옆 주차장에 길 고양들이 배설물을 싸고 있습니다   \n",
       "7                            공공시설 / 길거리 흡연자가 녀무 많습니다   \n",
       "8                                 벌래와 모기 하수구 냄새가 납니다   \n",
       "9                           바람이 동서족에서 불고 불쾌한 냄새가 납니다   \n",
       "\n",
       "                               spelling_res_sentence  \\\n",
       "0                                     음식물 쓰레기 냄새가 나요   \n",
       "1  전라북도 순창군 ᄋᄋ 면 마을 꼴 목길에 퇴비를 가져다 놓음 바람 이불 면골 목 안...   \n",
       "2                 인도에 폐기물 컨테이너가 있어 통행 불편 및 냄새로 불편합니다   \n",
       "3      이웃집에서 보일러 기름으로 추정되는 물질이 다량으로 유출되어 주변에 피해를 쥽니다   \n",
       "4                            동국대 신공학관 근처 하수 처리 냄새 신고   \n",
       "5  층간 소음 문제로 12년 된 아파트 하자 점검 서비스가 있나요 원룸 형 아파트인데요...   \n",
       "6                      건물 옆 주차장에 길 고양들이 배설물을 싸고 있습니다   \n",
       "7                             공공시설  길거리 흡연자가 너무 많습니다   \n",
       "8                                 벌래와 모기 하수구 냄새가 납니다   \n",
       "9                           바람이 동서족에서 불고 불쾌한 냄새가 납니다   \n",
       "\n",
       "                                        res_sentence  \n",
       "0                                     음식물 쓰레기 냄새가 나요  \n",
       "1  전라북도 순차군 아 면 마을 꼴 목기에 퇴비를 가져다 놓음 바람 이불 만골 목 안쪽...  \n",
       "2                 인도에 폐기물 컨테이너가 있어 통행 불편 및 냄새로 불편합니다  \n",
       "3      이웃집에서 보일러 기름으로 추정되는 물질이 다량으로 유출되어 주변에 피해를 잡니다  \n",
       "4                           동국도 신 공학관 근처 하수 처리 냄새 신고  \n",
       "5  증간 소음 문제로 12년 된 아파트 하자 점검 서비스가 있나요 원룸 형 아파트인데요...  \n",
       "6                      건물 옆 주차장에 길 고양들이 배설물을 싸고 있습니다  \n",
       "7                             공공시설  길거리 흡연자가 너무 많습니다  \n",
       "8                                 벌레와 모기 하수구 냄새가 납니다  \n",
       "9                          바람이 동서 족에서 불고 불쾌한 냄새가 납니다  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "층간소음 문제로 12년된 아파트 하자 점검 서비스가 있나요?\n",
      "원룸형 아파트 인데요. 옆집과 저희집 사이애 위치한 책장과 벽에 균열이 생겼는지 벽간 소음 발생이 심합니다. \n",
      "\n",
      "심지어 옆집 냄새도 넘어오는 데요. 하자 점검 서비스가 있을까요?\n",
      "\n",
      "층간 소음 문제로 12년 된 아파트 하자 점검 서비스가 있나요 원룸 형 아파트인데요 비스가 있을\n",
      "\n",
      "증간 소음 문제로 12년 된 아파트 하자 점검 서비스가 있나요 원룸 형 아파트인데요 비소가 있을\n"
     ]
    }
   ],
   "source": [
    "print(processed_df.iloc[5][0])\n",
    "print()\n",
    "\n",
    "print(processed_df.iloc[5][2])\n",
    "\n",
    "print()\n",
    "\n",
    "print(processed_df.iloc[5][3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
