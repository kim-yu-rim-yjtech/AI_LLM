{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yjtech2/Desktop/yurim/anaconda3/envs/venv-llm/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-11-19 10:25:55.766962: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-19 10:25:55.792110: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-19 10:25:56.156443: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yjtech2/Desktop/yurim/anaconda3/envs/venv-llm/lib/python3.8/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/home/yjtech2/Desktop/yurim/anaconda3/envs/venv-llm/lib/python3.8/site-packages/transformers/modeling_utils.py:399: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "# 모델 및 토크나이저 로드\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"j5ng/et5-typos-corrector\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"j5ng/et5-typos-corrector\")\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "# 맞춤법 교정 함수\n",
    "def correct_text(input_text):\n",
    "    input_encoding = tokenizer(\"맞춤법을 고쳐주세요: \" + input_text, return_tensors=\"pt\")\n",
    "    input_ids = input_encoding.input_ids.to(device)\n",
    "    attention_mask = input_encoding.attention_mask.to(device)\n",
    "    \n",
    "    output_encoding = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=128,\n",
    "        num_beams=5,\n",
    "        early_stopping=True,\n",
    "    )\n",
    "    output_text = tokenizer.decode(output_encoding[0], skip_special_tokens=True)\n",
    "    return output_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>제목</th>\n",
       "      <th>교정된_제목</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>악취 나는 뮬이 계속 흘러내려 물 을 오염시키고 있습니다.</td>\n",
       "      <td>냄새나는 뮬이 계속 흘러내려 물을 오염시키고 있습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>마을 골 목 길에  퇴비를 두어 악취 발생이 심하니 이동   조치해 주세요.</td>\n",
       "      <td>마을 골 목 길에 퇴비를 두어 냄새 발생이 심하니 이동 조치해 주세요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>노후된 모정 보수    요청ㅓ</td>\n",
       "      <td>노후된 모정 보수 요청.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>인도에 패기물 컨테이너 적치로 통행 불편</td>\n",
       "      <td>인도에 패기물 컨테이너 적치로 통행 불편.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>이웃집 에서 보일러 기름으로 추정되는 물질이 다량으로 유출되어 주변에 피해를 쥽니다</td>\n",
       "      <td>이웃집에서 보일러 기름으로 추정되는 물질이 다량으로 유출되어 주변에 피해를 쥽니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>복합악취의 수인한도는?</td>\n",
       "      <td>복합 악취의 수인한도는?.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>악취배출량 단위 및 산정방법은?</td>\n",
       "      <td>냄새 배출량 단위 및 산정 방법은?.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>단독 또는 공동주택에서 애완견 등을 사육하여 소음 등을 유발하는 경우 환경분쟁조정대...</td>\n",
       "      <td>단독 또는 공동주택에서 애완견 등을 사육하여 소음 등을 유발하는 경우 환경분쟁 조정...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>악취배출사업장 기술지원 및 공공환경시설 악취기술진단, 악취물질 측정·분석 관련 질의응답</td>\n",
       "      <td>냄새 배출 사업장 기술 지원 및 공공 환경 시설 악취 기술 진단 및 냄새 물질 측정...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>표시문의('소취', '냄새제거')</td>\n",
       "      <td>표시 문의 '소취','냄새 제거'.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    제목  \\\n",
       "0                     악취 나는 뮬이 계속 흘러내려 물 을 오염시키고 있습니다.   \n",
       "1           마을 골 목 길에  퇴비를 두어 악취 발생이 심하니 이동   조치해 주세요.   \n",
       "2                                     노후된 모정 보수    요청ㅓ   \n",
       "3                               인도에 패기물 컨테이너 적치로 통행 불편   \n",
       "4       이웃집 에서 보일러 기름으로 추정되는 물질이 다량으로 유출되어 주변에 피해를 쥽니다   \n",
       "..                                                 ...   \n",
       "111                                       복합악취의 수인한도는?   \n",
       "112                                  악취배출량 단위 및 산정방법은?   \n",
       "113  단독 또는 공동주택에서 애완견 등을 사육하여 소음 등을 유발하는 경우 환경분쟁조정대...   \n",
       "114   악취배출사업장 기술지원 및 공공환경시설 악취기술진단, 악취물질 측정·분석 관련 질의응답   \n",
       "115                                 표시문의('소취', '냄새제거')   \n",
       "\n",
       "                                                교정된_제목  \n",
       "0                       냄새나는 뮬이 계속 흘러내려 물을 오염시키고 있습니다.  \n",
       "1              마을 골 목 길에 퇴비를 두어 냄새 발생이 심하니 이동 조치해 주세요.  \n",
       "2                                        노후된 모정 보수 요청.  \n",
       "3                              인도에 패기물 컨테이너 적치로 통행 불편.  \n",
       "4       이웃집에서 보일러 기름으로 추정되는 물질이 다량으로 유출되어 주변에 피해를 쥽니다.  \n",
       "..                                                 ...  \n",
       "111                                     복합 악취의 수인한도는?.  \n",
       "112                               냄새 배출량 단위 및 산정 방법은?.  \n",
       "113  단독 또는 공동주택에서 애완견 등을 사육하여 소음 등을 유발하는 경우 환경분쟁 조정...  \n",
       "114  냄새 배출 사업장 기술 지원 및 공공 환경 시설 악취 기술 진단 및 냄새 물질 측정...  \n",
       "115                                표시 문의 '소취','냄새 제거'.  \n",
       "\n",
       "[116 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CSV 파일 로드\n",
    "df = pd.read_csv(\"/home/yjtech2/Desktop/yurim/LLM/Data/냄새_악취_포함.csv\", encoding=\"cp949\")\n",
    "\n",
    "# 맞춤법 교정 적용\n",
    "df[\"교정된_제목\"] = df[\"제목\"].apply(correct_text)\n",
    "df = df.iloc[:, [0, 2]]\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로드\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    10 non-null     object\n",
      "dtypes: object(1)\n",
      "memory usage: 208.0+ bytes\n",
      "None\n",
      "Applying spacing correction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing corrections: 100%|██████████| 10/10 [00:00<00:00, 301.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying spelling correction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing corrections: 100%|██████████| 10/10 [00:01<00:00,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Results ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import (\n",
    "    T5ForConditionalGeneration, \n",
    "    T5Tokenizer, \n",
    "    AutoModelForTokenClassification, \n",
    "    AutoTokenizer\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class TextCorrector:\n",
    "    def __init__(self):\n",
    "        # 띄어쓰기 모델 초기화\n",
    "        self.spacing_tokenizer = AutoTokenizer.from_pretrained(\"fiveflow/roberta-base-spacing\")\n",
    "        self.spacing_model = AutoModelForTokenClassification.from_pretrained(\"fiveflow/roberta-base-spacing\")\n",
    "        \n",
    "        # 맞춤법 모델 초기화\n",
    "        self.spelling_tokenizer = T5Tokenizer.from_pretrained('j5ng/et5-typos-corrector')\n",
    "        self.spelling_model = T5ForConditionalGeneration.from_pretrained('j5ng/et5-typos-corrector')\n",
    "        \n",
    "        # GPU 설정\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.spacing_model = self.spacing_model.to(self.device)\n",
    "        self.spelling_model = self.spelling_model.to(self.device)\n",
    "        \n",
    "        # 띄어쓰기 레이블\n",
    "        self.spacing_labels = [\"UNK\", \"PAD\", \"O\", \"B\", \"I\", \"E\", \"S\"]\n",
    "\n",
    "    # 띄어쓰기 교정\n",
    "    def correct_spacing(self, text):\n",
    "        if not isinstance(text, str) or not text.strip():\n",
    "            return \"\"\n",
    "            \n",
    "        try:\n",
    "            max_length = 512 - 2\n",
    "            org_text = text.replace(\" \", \"\")\n",
    "            results = []\n",
    "            \n",
    "            for start_idx in range(0, len(org_text), max_length):\n",
    "                chunk = org_text[start_idx:start_idx + max_length]\n",
    "                \n",
    "                # 토큰화\n",
    "                tokens = [self.spacing_tokenizer.cls_token_id]\n",
    "                tokens.extend(sum([self.spacing_tokenizer.encode(char)[1:-1] for char in chunk], []))\n",
    "                tokens.append(self.spacing_tokenizer.sep_token_id)\n",
    "                \n",
    "                # 예측\n",
    "                with torch.no_grad():\n",
    "                    inputs = torch.tensor([tokens]).to(self.device)\n",
    "                    outputs = self.spacing_model(inputs)\n",
    "                    predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "                \n",
    "                # 결과 생성\n",
    "                result = \"\"\n",
    "                for idx, pred in enumerate(predictions.squeeze()[1:-1]):\n",
    "                    if idx >= len(chunk):\n",
    "                        break\n",
    "                    result += chunk[idx]\n",
    "                    if self.spacing_labels[pred] in [\"E\", \"S\"]:\n",
    "                        result += \" \"\n",
    "                        \n",
    "                results.append(result.strip())\n",
    "            \n",
    "            return \" \".join(results).strip()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Spacing error: {str(e)}\")\n",
    "            return text\n",
    "\n",
    "    # 맞춤법 교정\n",
    "    def correct_spelling(self, text):\n",
    "        if not isinstance(text, str) or not text.strip():\n",
    "            return \"\"\n",
    "            \n",
    "        try:\n",
    "            max_length = 128 - 2\n",
    "            chunks = [text[i:i + max_length] for i in range(0, len(text), max_length)]\n",
    "            results = []\n",
    "            \n",
    "            for chunk in chunks:\n",
    "                inputs = self.spelling_tokenizer(\n",
    "                    \"맞춤법을 고쳐주세요: \" + chunk,\n",
    "                    return_tensors=\"pt\",\n",
    "                    truncation=True,\n",
    "                    max_length=max_length\n",
    "                ).to(self.device)\n",
    "                \n",
    "                outputs = self.spelling_model.generate(\n",
    "                    **inputs,\n",
    "                    max_length=max_length,\n",
    "                    num_beams=5,\n",
    "                    early_stopping=True\n",
    "                )\n",
    "                \n",
    "                result = self.spelling_tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "                if result:\n",
    "                    results.append(result)\n",
    "            \n",
    "            return \" \".join(results).strip() or \"\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Spelling error: {str(e)}\")\n",
    "            return \"\"\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "        return re.sub('[^\\w\\s]', '', text)\n",
    "\n",
    "def load_data(file_path):\n",
    "\n",
    "    \n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    print(df.info())\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_dataset(file_path):\n",
    "    # 데이터 로드 및 전처리기 초기화\n",
    "    print('데이터 로드')\n",
    "    df = load_data(file_path)\n",
    "    \n",
    "    corrector = TextCorrector()\n",
    "    \n",
    "    # 진행바 설정\n",
    "    tqdm.pandas(desc=\"Processing corrections\")\n",
    "    \n",
    "    # 띄어쓰기 교정\n",
    "    print(\"Applying spacing correction...\")\n",
    "    df['spacing_res_sentence'] = df['text'].progress_apply(corrector.correct_spacing)\n",
    "    \n",
    "    # 맞춤법 교정\n",
    "    print(\"Applying spelling correction...\")\n",
    "    df['spelling_res_sentence'] = df['spacing_res_sentence'].progress_apply(corrector.correct_spelling)\n",
    "    \n",
    "    # 텍스트 클리닝\n",
    "    df['spelling_res_sentence'] = df['spelling_res_sentence'].apply(corrector.clean_text)\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = '/home/yjtech2/Desktop/yurim/LLM/Data/text_test_data.xlsx'\n",
    "    result_df = process_dataset(file_path)\n",
    "    \n",
    "    print(\"\\n=== Results ===\")\n",
    "    result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spacing_res_sentence</th>\n",
       "      <th>spelling_res_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>음식물 쓰레기 냄세가 나요</td>\n",
       "      <td>음식물 쓰레기 냄세가 나요</td>\n",
       "      <td>음식물 쓰레기 냄새가 나요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>전라북도 순창군 ㅇㅇ면 마을 꼴목길에  퇴비를 가져다 놓음\\n바람이불면 골목안쪽으로...</td>\n",
       "      <td>전라북도 순창군 ㅇㅇ면 마을 꼴목길에 퇴비를 가져다 놓음 \\n바람 이불 면골 목안쪽...</td>\n",
       "      <td>전라북도 순창군 ᄋᄋ 면 마을 꼴 목길에 퇴비를 가져다 놓음 바람 이불 면골 목 안...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>인도에 폐기물 컨테이너가 있어 통행 불편 및 악취로 불편합니다.\\n발리조치해 주시기...</td>\n",
       "      <td>인도에 폐기물 컨테이너가 있어 통행 불편 및 악취로 불편합니다. \\n발 리조치 해주...</td>\n",
       "      <td>인도에 폐기물 컨테이너가 있어 통행 불편 및 냄새로 불편합니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이웃집 에서 보일러 기름으로 추정되는 물질이 다량으로 유출되어 주변에 피해를 쥽니다</td>\n",
       "      <td>이웃집에서 보일러 기름으로 추정되는 물질이 다량으로 유출되어 주변에 피해를 쥽니다</td>\n",
       "      <td>이웃집에서 보일러 기름으로 추정되는 물질이 다량으로 유출되어 주변에 피해를 쥽니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>동국대 신공학관 근처 하수 처리 냄세 신고</td>\n",
       "      <td>동국대 신공학관 근처 하수 처리 냄세 신고</td>\n",
       "      <td>동국대 신공학관 근처 하수 처리 냄새 신고</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>층간소음 문제로 12년된 아파트 하자 점검 서비스가 있나요?\\n원룸형 아파트 인데요...</td>\n",
       "      <td>층간 소음 문제로 12년 된 아파트 하자 점검 서비스가 있나요? \\n원룸 형아파트인...</td>\n",
       "      <td>층간 소음 문제로 12년 된 아파트 하자 점검 서비스가 있나요 원룸 형 아파트인데요</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>건물 옆 주차장에 길고양들이 배설물을 싸고 있습니다</td>\n",
       "      <td>건물 옆 주차장에 길 고양들이 배설물을 싸고 있습니다</td>\n",
       "      <td>건물 옆 주차장에 길 고양들이 배설물을 싸고 있습니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>공공시설/ 길거리 흡연자가 녀무 많습니다</td>\n",
       "      <td>공공시설 / 길거리 흡연자가 녀무 많습니다</td>\n",
       "      <td>공공시설  길거리 흡연자가 너무 많습니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>벌래와 모기 하수구냄새가 납니다</td>\n",
       "      <td>벌래와 모기 하수구 냄새가 납니다</td>\n",
       "      <td>벌래와 모기 하수구 냄새가 납니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>바람이 동서족에서 불고 불쾌한 냄새가 납니다</td>\n",
       "      <td>바람이 동서족에서 불고 불쾌한 냄새가 납니다</td>\n",
       "      <td>바람이 동서족에서 불고 불쾌한 냄새가 납니다</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                                     음식물 쓰레기 냄세가 나요   \n",
       "1  전라북도 순창군 ㅇㅇ면 마을 꼴목길에  퇴비를 가져다 놓음\\n바람이불면 골목안쪽으로...   \n",
       "2  인도에 폐기물 컨테이너가 있어 통행 불편 및 악취로 불편합니다.\\n발리조치해 주시기...   \n",
       "3     이웃집 에서 보일러 기름으로 추정되는 물질이 다량으로 유출되어 주변에 피해를 쥽니다   \n",
       "4                            동국대 신공학관 근처 하수 처리 냄세 신고   \n",
       "5  층간소음 문제로 12년된 아파트 하자 점검 서비스가 있나요?\\n원룸형 아파트 인데요...   \n",
       "6                       건물 옆 주차장에 길고양들이 배설물을 싸고 있습니다   \n",
       "7                             공공시설/ 길거리 흡연자가 녀무 많습니다   \n",
       "8                                  벌래와 모기 하수구냄새가 납니다   \n",
       "9                           바람이 동서족에서 불고 불쾌한 냄새가 납니다   \n",
       "\n",
       "                                spacing_res_sentence  \\\n",
       "0                                     음식물 쓰레기 냄세가 나요   \n",
       "1  전라북도 순창군 ㅇㅇ면 마을 꼴목길에 퇴비를 가져다 놓음 \\n바람 이불 면골 목안쪽...   \n",
       "2  인도에 폐기물 컨테이너가 있어 통행 불편 및 악취로 불편합니다. \\n발 리조치 해주...   \n",
       "3      이웃집에서 보일러 기름으로 추정되는 물질이 다량으로 유출되어 주변에 피해를 쥽니다   \n",
       "4                            동국대 신공학관 근처 하수 처리 냄세 신고   \n",
       "5  층간 소음 문제로 12년 된 아파트 하자 점검 서비스가 있나요? \\n원룸 형아파트인...   \n",
       "6                      건물 옆 주차장에 길 고양들이 배설물을 싸고 있습니다   \n",
       "7                            공공시설 / 길거리 흡연자가 녀무 많습니다   \n",
       "8                                 벌래와 모기 하수구 냄새가 납니다   \n",
       "9                           바람이 동서족에서 불고 불쾌한 냄새가 납니다   \n",
       "\n",
       "                               spelling_res_sentence  \n",
       "0                                     음식물 쓰레기 냄새가 나요  \n",
       "1  전라북도 순창군 ᄋᄋ 면 마을 꼴 목길에 퇴비를 가져다 놓음 바람 이불 면골 목 안...  \n",
       "2                 인도에 폐기물 컨테이너가 있어 통행 불편 및 냄새로 불편합니다  \n",
       "3      이웃집에서 보일러 기름으로 추정되는 물질이 다량으로 유출되어 주변에 피해를 쥽니다  \n",
       "4                            동국대 신공학관 근처 하수 처리 냄새 신고  \n",
       "5     층간 소음 문제로 12년 된 아파트 하자 점검 서비스가 있나요 원룸 형 아파트인데요  \n",
       "6                      건물 옆 주차장에 길 고양들이 배설물을 싸고 있습니다  \n",
       "7                             공공시설  길거리 흡연자가 너무 많습니다  \n",
       "8                                 벌래와 모기 하수구 냄새가 납니다  \n",
       "9                           바람이 동서족에서 불고 불쾌한 냄새가 납니다  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = result_df[['text', 'spacing_res_sentence', 'spelling_res_sentence']]\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text                     층간소음 문제로 12년된 아파트 하자 점검 서비스가 있나요?\\n원룸형 아파트 인데요...\n",
       "spacing_res_sentence     층간 소음 문제로 12년 된 아파트 하자 점검 서비스가 있나요? \\n원룸 형아파트인...\n",
       "spelling_res_sentence    층간 소음 문제로 12년 된 아파트 하자 점검 서비스가 있나요 원룸 형 아파트인데요...\n",
       "Name: 5, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.iloc[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 로드\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    10 non-null     object\n",
      "dtypes: object(1)\n",
      "memory usage: 208.0+ bytes\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying spacing correction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing corrections: 100%|██████████| 10/10 [00:00<00:00, 311.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying spelling correction...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing corrections: 100%|██████████| 10/10 [00:04<00:00,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Results ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import (\n",
    "    T5ForConditionalGeneration, \n",
    "    T5Tokenizer, \n",
    "    AutoModelForTokenClassification, \n",
    "    AutoTokenizer\n",
    ")\n",
    "from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class TextCorrector:\n",
    "    def __init__(self):\n",
    "        # 띄어쓰기 모델 초기화\n",
    "        self.spacing_tokenizer = AutoTokenizer.from_pretrained(\"fiveflow/roberta-base-spacing\")\n",
    "        self.spacing_model = AutoModelForTokenClassification.from_pretrained(\"fiveflow/roberta-base-spacing\")\n",
    "        \n",
    "        # 맞춤법 모델 초기화\n",
    "        self.spelling_tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\")\n",
    "        self.spelling_model = GPT2LMHeadModel.from_pretrained(\"skt/kogpt2-base-v2\")\n",
    "        \n",
    "        # GPU 설정\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.spacing_model = self.spacing_model.to(self.device)\n",
    "        self.spelling_model = self.spelling_model.to(self.device)\n",
    "        \n",
    "        # 띄어쓰기 레이블\n",
    "        self.spacing_labels = [\"UNK\", \"PAD\", \"O\", \"B\", \"I\", \"E\", \"S\"]\n",
    "\n",
    "    # 띄어쓰기 교정\n",
    "    def correct_spacing(self, text):\n",
    "        if not isinstance(text, str) or not text.strip():\n",
    "            return \"\"\n",
    "            \n",
    "        try:\n",
    "            max_length = 512 - 2\n",
    "            org_text = text.replace(\" \", \"\")\n",
    "            results = []\n",
    "            \n",
    "            for start_idx in range(0, len(org_text), max_length):\n",
    "                chunk = org_text[start_idx:start_idx + max_length]\n",
    "                \n",
    "                # 토큰화\n",
    "                tokens = [self.spacing_tokenizer.cls_token_id]\n",
    "                tokens.extend(sum([self.spacing_tokenizer.encode(char)[1:-1] for char in chunk], []))\n",
    "                tokens.append(self.spacing_tokenizer.sep_token_id)\n",
    "                \n",
    "                # 예측\n",
    "                with torch.no_grad():\n",
    "                    inputs = torch.tensor([tokens]).to(self.device)\n",
    "                    outputs = self.spacing_model(inputs)\n",
    "                    predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "                \n",
    "                # 결과 생성\n",
    "                result = \"\"\n",
    "                for idx, pred in enumerate(predictions.squeeze()[1:-1]):\n",
    "                    if idx >= len(chunk):\n",
    "                        break\n",
    "                    result += chunk[idx]\n",
    "                    if self.spacing_labels[pred] in [\"E\", \"S\"]:\n",
    "                        result += \" \"\n",
    "                        \n",
    "                results.append(result.strip())\n",
    "            \n",
    "            return \" \".join(results).strip()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Spacing error: {str(e)}\")\n",
    "            return text\n",
    "\n",
    "    # 맞춤법 교정\n",
    "    def correct_spelling(self, text):\n",
    "        if not isinstance(text, str) or not text.strip():\n",
    "            return \"\"\n",
    "            \n",
    "        try:\n",
    "            max_length = 128 - 2\n",
    "            chunks = [text[i:i + max_length] for i in range(0, len(text), max_length)]\n",
    "            results = []\n",
    "            \n",
    "            for chunk in chunks:\n",
    "                inputs = self.spelling_tokenizer(\n",
    "                    \"맞춤법을 고쳐주세요: \" + chunk,\n",
    "                    return_tensors=\"pt\",\n",
    "                    truncation=True,\n",
    "                    max_length=max_length\n",
    "                ).to(self.device)\n",
    "                \n",
    "                outputs = self.spelling_model.generate(\n",
    "                    **inputs,\n",
    "                    max_length=max_length,\n",
    "                    num_beams=5,\n",
    "                    early_stopping=True\n",
    "                )\n",
    "                \n",
    "                result = self.spelling_tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "                if result:\n",
    "                    results.append(result)\n",
    "            \n",
    "            return \" \".join(results).strip() or \"\"\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Spelling error: {str(e)}\")\n",
    "            return \"\"\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        if not isinstance(text, str):\n",
    "            return \"\"\n",
    "        return re.sub('[^\\w\\s]', '', text)\n",
    "\n",
    "def load_data(file_path):\n",
    "\n",
    "    \n",
    "    df = pd.read_excel(file_path)\n",
    "    \n",
    "    print(df.info())\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_dataset(file_path):\n",
    "    # 데이터 로드 및 전처리기 초기화\n",
    "    print('데이터 로드')\n",
    "    df = load_data(file_path)\n",
    "    \n",
    "    corrector = TextCorrector()\n",
    "    \n",
    "    # 진행바 설정\n",
    "    tqdm.pandas(desc=\"Processing corrections\")\n",
    "    \n",
    "    # 띄어쓰기 교정\n",
    "    print(\"Applying spacing correction...\")\n",
    "    df['spacing_res_sentence'] = df['text'].progress_apply(corrector.correct_spacing)\n",
    "    \n",
    "    # 맞춤법 교정\n",
    "    print(\"Applying spelling correction...\")\n",
    "    df['spelling_res_sentence'] = df['spacing_res_sentence'].progress_apply(corrector.correct_spelling)\n",
    "    \n",
    "    # 텍스트 클리닝\n",
    "    df['spelling_res_sentence'] = df['spelling_res_sentence'].apply(corrector.clean_text)\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = '/home/yjtech2/Desktop/yurim/LLM/Data/text_test_data.xlsx'\n",
    "    result_df = process_dataset(file_path)\n",
    "    \n",
    "    print(\"\\n=== Results ===\")\n",
    "    result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spacing_res_sentence</th>\n",
       "      <th>spelling_res_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>음식물 쓰레기 냄세가 나요</td>\n",
       "      <td>음식물 쓰레기 냄세가 나요</td>\n",
       "      <td>맞춤법을 고쳐주세요 음식물 쓰레기 냄세가 나요 음식물 쓰레기 냄세가 나요\\n 음식물...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>전라북도 순창군 ㅇㅇ면 마을 꼴목길에  퇴비를 가져다 놓음\\n바람이불면 골목안쪽으로...</td>\n",
       "      <td>전라북도 순창군 ㅇㅇ면 마을 꼴목길에 퇴비를 가져다 놓음 \\n바람 이불 면골 목안쪽...</td>\n",
       "      <td>맞춤법을 고쳐주세요 전라북도 순창군 ᄋᄋ면 마을 꼴목길에 퇴비를 가져다 놓음 \\n바...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>인도에 폐기물 컨테이너가 있어 통행 불편 및 악취로 불편합니다.\\n발리조치해 주시기...</td>\n",
       "      <td>인도에 폐기물 컨테이너가 있어 통행 불편 및 악취로 불편합니다. \\n발 리조치 해주...</td>\n",
       "      <td>맞춤법을 고쳐주세요 인도에 폐기물 컨테이너가 있어 통행 불편 및 악취로 불편합니다 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이웃집 에서 보일러 기름으로 추정되는 물질이 다량으로 유출되어 주변에 피해를 쥽니다</td>\n",
       "      <td>이웃집에서 보일러 기름으로 추정되는 물질이 다량으로 유출되어 주변에 피해를 쥽니다</td>\n",
       "      <td>맞춤법을 고쳐주세요 이웃집에서 보일러 기름으로 추정되는 물질이 다량으로 유출되어 주...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>동국대 신공학관 근처 하수 처리 냄세 신고</td>\n",
       "      <td>동국대 신공학관 근처 하수 처리 냄세 신고</td>\n",
       "      <td>맞춤법을 고쳐주세요 동국대 신공학관 근처 하수 처리 냄세 신고하세요 동국대 신공학관...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>층간소음 문제로 12년된 아파트 하자 점검 서비스가 있나요?\\n원룸형 아파트 인데요...</td>\n",
       "      <td>층간 소음 문제로 12년 된 아파트 하자 점검 서비스가 있나요? \\n원룸 형아파트인...</td>\n",
       "      <td>맞춤법을 고쳐주세요 층간 소음 문제로 12년 된 아파트 하자 점검 서비스가 있나요 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>건물 옆 주차장에 길고양들이 배설물을 싸고 있습니다</td>\n",
       "      <td>건물 옆 주차장에 길 고양들이 배설물을 싸고 있습니다</td>\n",
       "      <td>맞춤법을 고쳐주세요 건물 옆 주차장에 길 고양들이 배설물을 싸고 있습니다\\n고양들이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>공공시설/ 길거리 흡연자가 녀무 많습니다</td>\n",
       "      <td>공공시설 / 길거리 흡연자가 녀무 많습니다</td>\n",
       "      <td>맞춤법을 고쳐주세요 공공시설  길거리 흡연자가 녀무 많습니다</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>벌래와 모기 하수구냄새가 납니다</td>\n",
       "      <td>벌래와 모기 하수구 냄새가 납니다</td>\n",
       "      <td>맞춤법을 고쳐주세요 벌래와 모기 하수구 냄새가 납니다\\n벌래와 모기 하수구 냄새가 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>바람이 동서족에서 불고 불쾌한 냄새가 납니다</td>\n",
       "      <td>바람이 동서족에서 불고 불쾌한 냄새가 납니다</td>\n",
       "      <td>맞춤법을 고쳐주세요 바람이 동서족에서 불고 불쾌한 냄새가 납니다\\n바람이 불고 불쾌...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                                     음식물 쓰레기 냄세가 나요   \n",
       "1  전라북도 순창군 ㅇㅇ면 마을 꼴목길에  퇴비를 가져다 놓음\\n바람이불면 골목안쪽으로...   \n",
       "2  인도에 폐기물 컨테이너가 있어 통행 불편 및 악취로 불편합니다.\\n발리조치해 주시기...   \n",
       "3     이웃집 에서 보일러 기름으로 추정되는 물질이 다량으로 유출되어 주변에 피해를 쥽니다   \n",
       "4                            동국대 신공학관 근처 하수 처리 냄세 신고   \n",
       "5  층간소음 문제로 12년된 아파트 하자 점검 서비스가 있나요?\\n원룸형 아파트 인데요...   \n",
       "6                       건물 옆 주차장에 길고양들이 배설물을 싸고 있습니다   \n",
       "7                             공공시설/ 길거리 흡연자가 녀무 많습니다   \n",
       "8                                  벌래와 모기 하수구냄새가 납니다   \n",
       "9                           바람이 동서족에서 불고 불쾌한 냄새가 납니다   \n",
       "\n",
       "                                spacing_res_sentence  \\\n",
       "0                                     음식물 쓰레기 냄세가 나요   \n",
       "1  전라북도 순창군 ㅇㅇ면 마을 꼴목길에 퇴비를 가져다 놓음 \\n바람 이불 면골 목안쪽...   \n",
       "2  인도에 폐기물 컨테이너가 있어 통행 불편 및 악취로 불편합니다. \\n발 리조치 해주...   \n",
       "3      이웃집에서 보일러 기름으로 추정되는 물질이 다량으로 유출되어 주변에 피해를 쥽니다   \n",
       "4                            동국대 신공학관 근처 하수 처리 냄세 신고   \n",
       "5  층간 소음 문제로 12년 된 아파트 하자 점검 서비스가 있나요? \\n원룸 형아파트인...   \n",
       "6                      건물 옆 주차장에 길 고양들이 배설물을 싸고 있습니다   \n",
       "7                            공공시설 / 길거리 흡연자가 녀무 많습니다   \n",
       "8                                 벌래와 모기 하수구 냄새가 납니다   \n",
       "9                           바람이 동서족에서 불고 불쾌한 냄새가 납니다   \n",
       "\n",
       "                               spelling_res_sentence  \n",
       "0  맞춤법을 고쳐주세요 음식물 쓰레기 냄세가 나요 음식물 쓰레기 냄세가 나요\\n 음식물...  \n",
       "1  맞춤법을 고쳐주세요 전라북도 순창군 ᄋᄋ면 마을 꼴목길에 퇴비를 가져다 놓음 \\n바...  \n",
       "2  맞춤법을 고쳐주세요 인도에 폐기물 컨테이너가 있어 통행 불편 및 악취로 불편합니다 ...  \n",
       "3  맞춤법을 고쳐주세요 이웃집에서 보일러 기름으로 추정되는 물질이 다량으로 유출되어 주...  \n",
       "4  맞춤법을 고쳐주세요 동국대 신공학관 근처 하수 처리 냄세 신고하세요 동국대 신공학관...  \n",
       "5  맞춤법을 고쳐주세요 층간 소음 문제로 12년 된 아파트 하자 점검 서비스가 있나요 ...  \n",
       "6  맞춤법을 고쳐주세요 건물 옆 주차장에 길 고양들이 배설물을 싸고 있습니다\\n고양들이...  \n",
       "7                  맞춤법을 고쳐주세요 공공시설  길거리 흡연자가 녀무 많습니다  \n",
       "8  맞춤법을 고쳐주세요 벌래와 모기 하수구 냄새가 납니다\\n벌래와 모기 하수구 냄새가 ...  \n",
       "9  맞춤법을 고쳐주세요 바람이 동서족에서 불고 불쾌한 냄새가 납니다\\n바람이 불고 불쾌...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df = result_df[['text', 'spacing_res_sentence', 'spelling_res_sentence']]\n",
    "\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 입력 ===\n",
      "오늘 날씨가 좋읍니다.\n",
      "\n",
      "=== 교정된 출력 ===\n",
      "오늘 날씨가 좋읍니다. 고맙습니다.\"\n",
      "\"그런데 이게 웬일입니까?\"\n",
      "\"아니오. 그건 그렇고요.\"\n",
      "\"어떻게 된 일입니까?\"\n",
      "\"이제야 알겠습니다.\"\n",
      "\"무슨 말씀을 하시는 겁니까?\"\n",
      "\"네, 저도 알고 있습니다.\"\n",
      "\"뭐라고요? 무슨 말씀을 하시는 겁니까?\"\n",
      "\"저도 잘 모르겠습니다만.\"\n",
      "\"그렇지 않습니까?\"\n",
      "\"왜 그러십니까?\"\n",
      "\"우선 당신들한테 물어봐야 할 것 아닙니까?\"\n",
      "\"당신들한테\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import re\n",
    "\n",
    "# 모델 및 토크나이저 로드\n",
    "model = GPT2LMHeadModel.from_pretrained(\"skt/kogpt2-base-v2\")\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"skt/kogpt2-base-v2\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "def split_sentences(text):\n",
    "    # 문장 단위로 분리\n",
    "    sentences = re.split(r'(?<=[.!?]) +', text.strip())\n",
    "    return sentences\n",
    "\n",
    "def generate_text(input_text):\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    # 텍스트 생성\n",
    "    outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_length=128,\n",
    "        num_beams=5,\n",
    "        repetition_penalty=2.0,\n",
    "        temperature=0.8,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "def correct_text(input_text):\n",
    "    sentences = split_sentences(input_text)\n",
    "    corrected_sentences = [generate_text(sentence) for sentence in sentences]\n",
    "    return \" \".join(corrected_sentences)\n",
    "\n",
    "# 예제 입력\n",
    "input_text = \"오늘 날씨가 좋읍니다.\"\n",
    "corrected_text = correct_text(input_text)\n",
    "print(\"=== 입력 ===\")\n",
    "print(input_text)\n",
    "print(\"\\n=== 교정된 출력 ===\")\n",
    "print(corrected_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 08:57:24.030602: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-05 08:57:24.054178: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-05 08:57:24.464449: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요? 포항 시 오천읍에 거주하는 이강일입니다.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"j5ng/et5-typos-corrector\")\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"j5ng/et5-typos-corrector\")\n",
    "\n",
    "def correct_text_et5(input_text):\n",
    "    input_ids = tokenizer(\"맞춤법을 고쳐주세요: \" + input_text, return_tensors=\"pt\", truncation=True).input_ids\n",
    "    outputs = model.generate(input_ids, max_length=128, num_beams=5, early_stopping=True)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "input_text = \"안녕하세요. 포항시 오천읍에 거주하는 이강일입니다.  저는 지난 11월 13일 이후로 집에서 나오는 수돗물에서 고약한 냄새  가 나기 시작했습니다. 처음에는 아파트 물탱크의 문제가  있는 줄 알고 대수롭지 않게 여 겠는데 냄새가 계속 나서 걱정이  돼서 신고합니다. 현재 수돗물에서 흙냄새와 곰팡이  냄새가 나고 그래서 설거지나 세수 는 물론 물을 마실 수가 없습니다.생수로 대체해서 사용하고 있는데 이 문제로 매우 불편을 겪고 있습니다.  포항시 수돗물 원수의 40%를 공급 하는 경주 안개 때문에서 녹조  현상이 발생했다고 들었고 남조류 에서 발생한 지오스민이 냄새를  유발한다고 합니다. 이 문제에 대한 빠른 대응을 부탁  드립니다. 감사합니다.\"\n",
    "corrected_text = correct_text_et5(input_text)\n",
    "print(corrected_text)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
